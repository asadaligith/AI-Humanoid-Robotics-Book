"use strict";(self.webpackChunkai_humanoid_robotics_book=self.webpackChunkai_humanoid_robotics_book||[]).push([[4634],{6809:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"modules/module-04-vla-vision-language-action/chapter-02-whisper","title":"Chapter 2: Speech Recognition with Whisper","description":"Implement speech-to-text using OpenAI Whisper","source":"@site/docs/modules/module-04-vla-vision-language-action/chapter-02-whisper.md","sourceDirName":"modules/module-04-vla-vision-language-action","slug":"/modules/module-04-vla-vision-language-action/chapter-02-whisper","permalink":"/docs/modules/module-04-vla-vision-language-action/chapter-02-whisper","draft":false,"unlisted":false,"editUrl":"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/tree/main/docs/modules/module-04-vla-vision-language-action/chapter-02-whisper.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2: Speech Recognition with Whisper","description":"Implement speech-to-text using OpenAI Whisper","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"1\ufe0f\u20e3 Introduction to VLA","permalink":"/docs/modules/module-04-vla-vision-language-action/chapter-01-introduction"},"next":{"title":"3\ufe0f\u20e3 LLM Task Planning","permalink":"/docs/modules/module-04-vla-vision-language-action/chapter-03-llm-planning"}}');var s=i(4848),o=i(8453);const r={title:"Chapter 2: Speech Recognition with Whisper",description:"Implement speech-to-text using OpenAI Whisper",sidebar_position:2},a="Chapter 2: Speech Recognition with Whisper",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Whisper Setup",id:"whisper-setup",level:2},{value:"Python Integration",id:"python-integration",level:2},{value:"ROS 2 Node",id:"ros-2-node",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-2-speech-recognition-with-whisper",children:"Chapter 2: Speech Recognition with Whisper"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Install"})," and run Whisper locally"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Integrate"})," Whisper with ROS 2"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Optimize"})," for real-time speech recognition"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"whisper-setup",children:"Whisper Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install openai-whisper\n"})}),"\n",(0,s.jsx)(n.h2,{id:"python-integration",children:"Python Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import whisper\r\n\r\nmodel = whisper.load_model("base")\r\nresult = model.transcribe("command.wav")\r\nprint(result["text"])  # "Pick up the red cube"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"ros-2-node",children:"ROS 2 Node"}),"\n",(0,s.jsx)(n.p,{children:"Create a node that subscribes to audio and publishes transcribed text."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Code Example"}),": See ",(0,s.jsx)(n.code,{children:"examples/module-04-vla/example-01-vla-pipeline/whisper_node.py"})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Next"}),": ",(0,s.jsx)(n.a,{href:"/docs/modules/module-04-vla-vision-language-action/chapter-03-llm-planning",children:"Chapter 3: LLM Task Planning"})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reading Time"}),": 20 minutes\r\n",(0,s.jsx)(n.strong,{children:"Hands-On Time"}),": 40 minutes"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);