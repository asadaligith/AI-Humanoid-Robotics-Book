"use strict";(self.webpackChunkai_humanoid_robotics_book=self.webpackChunkai_humanoid_robotics_book||[]).push([[4379],{3564:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"rag-chatbot/setup","title":"RAG Chatbot Setup Guide","description":"Prerequisites","source":"@site/docs/rag-chatbot/setup.md","sourceDirName":"rag-chatbot","slug":"/rag-chatbot/setup","permalink":"/docs/rag-chatbot/setup","draft":false,"unlisted":false,"editUrl":"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/tree/main/docs/rag-chatbot/setup.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"RAG Chatbot Architecture","permalink":"/docs/rag-chatbot/architecture"},"next":{"title":"RAG Chatbot Deployment Guide","permalink":"/docs/rag-chatbot/deployment"}}');var s=r(4848),i=r(8453);const a={},o="RAG Chatbot Setup Guide",c={},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Requirements File",id:"requirements-file",level:2},{value:"Environment Configuration",id:"environment-configuration",level:2},{value:"Database Setup",id:"database-setup",level:2},{value:"1. Create Neon PostgreSQL Database",id:"1-create-neon-postgresql-database",level:3},{value:"2. Setup Qdrant Vector Database",id:"2-setup-qdrant-vector-database",level:3},{value:"Ingesting Documentation",id:"ingesting-documentation",level:2},{value:"Running the API",id:"running-the-api",level:2},{value:"Testing the API",id:"testing-the-api",level:2},{value:"Docker Deployment",id:"docker-deployment",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Issue: Database connection fails",id:"issue-database-connection-fails",level:3},{value:"Issue: Qdrant connection timeout",id:"issue-qdrant-connection-timeout",level:3},{value:"Issue: Embeddings failing",id:"issue-embeddings-failing",level:3},{value:"References",id:"references",level:2}];function l(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"rag-chatbot-setup-guide",children:"RAG Chatbot Setup Guide"})}),"\n",(0,s.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Python 3.9+"}),"\n",(0,s.jsx)(e.li,{children:"Node.js 18+ (for Docusaurus integration)"}),"\n",(0,s.jsx)(e.li,{children:"Git"}),"\n",(0,s.jsxs)(e.li,{children:["API Keys:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Anthropic Claude API"}),"\n",(0,s.jsx)(e.li,{children:"OpenAI API (for embeddings)"}),"\n",(0,s.jsx)(e.li,{children:"Qdrant Cloud account"}),"\n",(0,s.jsx)(e.li,{children:"Neon PostgreSQL account"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Clone repository\r\ngit clone https://github.com/asadaligith/AI-Humanoid-Robotics-Book.git\r\ncd AI-Humanoid-Robotics-Book\r\n\r\n# Create chatbot directory\r\nmkdir -p chatbot\r\ncd chatbot\r\n\r\n# Create virtual environment\r\npython3 -m venv venv\r\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\r\n\r\n# Install dependencies\r\npip install -r requirements.txt\n"})}),"\n",(0,s.jsx)(e.h2,{id:"requirements-file",children:"Requirements File"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"chatbot/requirements.txt"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-txt",children:"# Core dependencies\r\nfastapi==0.104.1\r\nuvicorn[standard]==0.24.0\r\nanthropic==0.7.7\r\nopenai==1.3.7\r\nqdrant-client==1.7.0\r\npsycopg2-binary==2.9.9\r\n\r\n# Data processing\r\nlangchain==0.0.340\r\npython-dotenv==1.0.0\r\npydantic==2.5.0\r\n\r\n# Utilities\r\nredis==5.0.1\r\ntenacity==8.2.3\r\nmarkdown==3.5.1\r\npython-multipart==0.0.6\r\n\r\n# Development\r\npytest==7.4.3\r\npytest-asyncio==0.21.1\r\nblack==23.11.0\n"})}),"\n",(0,s.jsx)(e.h2,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:".env"})," file:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# API Keys\r\nANTHROPIC_API_KEY=sk-ant-api03-...\r\nOPENAI_API_KEY=sk-...\r\n\r\n# Qdrant\r\nQDRANT_URL=https://your-cluster.qdrant.io:6333\r\nQDRANT_API_KEY=your-qdrant-api-key\r\nQDRANT_COLLECTION=course_docs\r\n\r\n# PostgreSQL (Neon)\r\nDATABASE_URL=postgresql://user:password@your-project.neon.tech/chatbot?sslmode=require\r\nDB_POOL_SIZE=10\r\nDB_MAX_OVERFLOW=20\r\n\r\n# Redis (Optional)\r\nREDIS_URL=redis://localhost:6379/0\r\n\r\n# Application\r\nAPP_ENV=development\r\nAPP_PORT=8000\r\nAPP_HOST=0.0.0.0\r\nLOG_LEVEL=INFO\r\n\r\n# Security\r\nAPI_RATE_LIMIT=10  # requests per minute\r\nMAX_CONTEXT_LENGTH=8000\r\nMAX_RESPONSE_TOKENS=2048\n"})}),"\n",(0,s.jsx)(e.h2,{id:"database-setup",children:"Database Setup"}),"\n",(0,s.jsx)(e.h3,{id:"1-create-neon-postgresql-database",children:"1. Create Neon PostgreSQL Database"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Sign up at https://neon.tech\r\n# Create new project: "chatbot"\r\n# Copy connection string\r\n\r\n# Initialize database\r\npython scripts/init_database.py\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.code,{children:"scripts/init_database.py"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\r\nimport psycopg2\r\nimport os\r\nfrom dotenv import load_dotenv\r\n\r\nload_dotenv()\r\n\r\n# Connect to database\r\nconn = psycopg2.connect(os.getenv('DATABASE_URL'))\r\ncur = conn.cursor()\r\n\r\n# Create tables\r\nwith open('schema.sql', 'r') as f:\r\n    cur.execute(f.read())\r\n\r\nconn.commit()\r\ncur.close()\r\nconn.close()\r\n\r\nprint(\"Database initialized successfully!\")\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.code,{children:"schema.sql"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"-- Enable UUID extension\r\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\r\n\r\n-- Documents table\r\nCREATE TABLE IF NOT EXISTS documents (\r\n    id SERIAL PRIMARY KEY,\r\n    title VARCHAR(255) NOT NULL,\r\n    url VARCHAR(512),\r\n    module VARCHAR(50),\r\n    chapter VARCHAR(50),\r\n    content_hash VARCHAR(64) UNIQUE,\r\n    chunk_count INTEGER DEFAULT 0,\r\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\r\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Chat sessions\r\nCREATE TABLE IF NOT EXISTS chat_sessions (\r\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\r\n    user_id VARCHAR(100),\r\n    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\r\n    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\r\n    message_count INTEGER DEFAULT 0,\r\n    metadata JSONB\r\n);\r\n\r\n-- Chat messages\r\nCREATE TABLE IF NOT EXISTS chat_messages (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id) ON DELETE CASCADE,\r\n    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant')),\r\n    content TEXT NOT NULL,\r\n    tokens_used INTEGER,\r\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Retrieved documents\r\nCREATE TABLE IF NOT EXISTS retrieved_documents (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id) ON DELETE CASCADE,\r\n    document_id INTEGER REFERENCES documents(id),\r\n    relevance_score FLOAT,\r\n    query TEXT,\r\n    rank INTEGER,\r\n    retrieved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- User feedback\r\nCREATE TABLE IF NOT EXISTS feedback (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id) ON DELETE CASCADE,\r\n    message_id INTEGER,\r\n    rating INTEGER CHECK (rating BETWEEN 1 AND 5),\r\n    comment TEXT,\r\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Query analytics\r\nCREATE TABLE IF NOT EXISTS query_analytics (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id) ON DELETE CASCADE,\r\n    query TEXT NOT NULL,\r\n    response_time_ms INTEGER,\r\n    contexts_retrieved INTEGER,\r\n    model_used VARCHAR(50),\r\n    tokens_used INTEGER,\r\n    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Indexes\r\nCREATE INDEX IF NOT EXISTS idx_sessions_user ON chat_sessions(user_id);\r\nCREATE INDEX IF NOT EXISTS idx_sessions_activity ON chat_sessions(last_activity DESC);\r\nCREATE INDEX IF NOT EXISTS idx_messages_session ON chat_messages(session_id);\r\nCREATE INDEX IF NOT EXISTS idx_documents_module ON documents(module);\r\nCREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(content_hash);\r\nCREATE INDEX IF NOT EXISTS idx_retrieved_query ON retrieved_documents(query);\r\nCREATE INDEX IF NOT EXISTS idx_analytics_timestamp ON query_analytics(timestamp DESC);\r\n\r\n-- Function to update last_activity\r\nCREATE OR REPLACE FUNCTION update_session_activity()\r\nRETURNS TRIGGER AS $$\r\nBEGIN\r\n    UPDATE chat_sessions\r\n    SET last_activity = CURRENT_TIMESTAMP,\r\n        message_count = message_count + 1\r\n    WHERE id = NEW.session_id;\r\n    RETURN NEW;\r\nEND;\r\n$$ LANGUAGE plpgsql;\r\n\r\n-- Trigger to auto-update session activity\r\nCREATE TRIGGER update_session_activity_trigger\r\nAFTER INSERT ON chat_messages\r\nFOR EACH ROW\r\nEXECUTE FUNCTION update_session_activity();\n"})}),"\n",(0,s.jsx)(e.h3,{id:"2-setup-qdrant-vector-database",children:"2. Setup Qdrant Vector Database"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Sign up at https://cloud.qdrant.io\r\n# Create cluster: "chatbot-vectors"\r\n# Copy API key and URL\r\n\r\n# Initialize collection\r\npython scripts/init_qdrant.py\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.code,{children:"scripts/init_qdrant.py"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\nfrom qdrant_client import QdrantClient\r\nfrom qdrant_client.models import Distance, VectorParams\r\nimport os\r\nfrom dotenv import load_dotenv\r\n\r\nload_dotenv()\r\n\r\n# Connect to Qdrant\r\nclient = QdrantClient(\r\n    url=os.getenv(\'QDRANT_URL\'),\r\n    api_key=os.getenv(\'QDRANT_API_KEY\')\r\n)\r\n\r\ncollection_name = os.getenv(\'QDRANT_COLLECTION\', \'course_docs\')\r\n\r\n# Create collection\r\nclient.recreate_collection(\r\n    collection_name=collection_name,\r\n    vectors_config=VectorParams(\r\n        size=1536,  # OpenAI text-embedding-3-small\r\n        distance=Distance.COSINE\r\n    )\r\n)\r\n\r\n# Create payload indexes\r\nclient.create_payload_index(\r\n    collection_name=collection_name,\r\n    field_name="module",\r\n    field_schema="keyword"\r\n)\r\n\r\nclient.create_payload_index(\r\n    collection_name=collection_name,\r\n    field_name="chapter",\r\n    field_schema="keyword"\r\n)\r\n\r\nclient.create_payload_index(\r\n    collection_name=collection_name,\r\n    field_name="title",\r\n    field_schema="text"\r\n)\r\n\r\nprint(f"Qdrant collection \'{collection_name}\' created successfully!")\n'})}),"\n",(0,s.jsx)(e.h2,{id:"ingesting-documentation",children:"Ingesting Documentation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Ingest all course documentation\r\npython scripts/ingest_docs.py --docs-path ../docs\r\n\r\n# Ingest specific module\r\npython scripts/ingest_docs.py --docs-path ../docs/modules/module-01-ros2-fundamentals\r\n\r\n# Re-index (clears and re-ingests)\r\npython scripts/ingest_docs.py --docs-path ../docs --reindex\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.code,{children:"scripts/ingest_docs.py"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nIngest course documentation into Qdrant and PostgreSQL\r\n"""\r\nimport argparse\r\nfrom pathlib import Path\r\nimport hashlib\r\nfrom typing import List, Dict\r\nfrom qdrant_client import QdrantClient\r\nfrom qdrant_client.models import PointStruct\r\nfrom openai import OpenAI\r\nimport psycopg2\r\nimport os\r\nfrom dotenv import load_dotenv\r\nimport re\r\n\r\nload_dotenv()\r\n\r\nclass DocumentIngester:\r\n    def __init__(self):\r\n        # Initialize clients\r\n        self.qdrant = QdrantClient(\r\n            url=os.getenv(\'QDRANT_URL\'),\r\n            api_key=os.getenv(\'QDRANT_API_KEY\')\r\n        )\r\n        self.openai = OpenAI(api_key=os.getenv(\'OPENAI_API_KEY\'))\r\n        self.db = psycopg2.connect(os.getenv(\'DATABASE_URL\'))\r\n        self.collection_name = os.getenv(\'QDRANT_COLLECTION\', \'course_docs\')\r\n\r\n    def ingest_directory(self, docs_path: str, reindex: bool = False):\r\n        """Ingest all markdown files."""\r\n        docs_path = Path(docs_path)\r\n\r\n        if reindex:\r\n            print("Clearing existing data...")\r\n            self.clear_data()\r\n\r\n        print(f"Scanning {docs_path}...")\r\n        md_files = list(docs_path.rglob("*.md"))\r\n        print(f"Found {len(md_files)} markdown files")\r\n\r\n        total_chunks = 0\r\n\r\n        for md_file in md_files:\r\n            print(f"\\nProcessing: {md_file.name}")\r\n            chunks = self.process_file(md_file)\r\n            total_chunks += len(chunks)\r\n            print(f"  Created {len(chunks)} chunks")\r\n\r\n        print(f"\\n\u2713 Ingestion complete! Total chunks: {total_chunks}")\r\n\r\n    def process_file(self, file_path: Path) -> List[Dict]:\r\n        """Process a single markdown file."""\r\n        content = file_path.read_text(encoding=\'utf-8\')\r\n\r\n        # Extract metadata\r\n        metadata = self.extract_metadata(file_path, content)\r\n\r\n        # Check if already ingested\r\n        content_hash = hashlib.sha256(content.encode()).hexdigest()\r\n        if self.is_already_ingested(content_hash):\r\n            print(f"  Skipping (already ingested)")\r\n            return []\r\n\r\n        # Chunk document\r\n        chunks = self.chunk_document(content, metadata)\r\n\r\n        # Generate embeddings\r\n        texts = [chunk[\'text\'] for chunk in chunks]\r\n        embeddings = self.generate_embeddings(texts)\r\n\r\n        # Store in Qdrant\r\n        points = []\r\n        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\r\n            point_id = hash(f"{content_hash}_{i}") % (10 ** 10)\r\n            points.append(\r\n                PointStruct(\r\n                    id=point_id,\r\n                    vector=embedding,\r\n                    payload=chunk\r\n                )\r\n            )\r\n\r\n        self.qdrant.upsert(\r\n            collection_name=self.collection_name,\r\n            points=points\r\n        )\r\n\r\n        # Store metadata in PostgreSQL\r\n        self.store_metadata(metadata, content_hash, len(chunks))\r\n\r\n        return chunks\r\n\r\n    def extract_metadata(self, file_path: Path, content: str) -> Dict:\r\n        """Extract metadata from file path and content."""\r\n        # Parse file path\r\n        parts = file_path.parts\r\n        module = None\r\n        chapter = None\r\n\r\n        for part in parts:\r\n            if \'module-\' in part:\r\n                module = part\r\n            if \'chapter-\' in part:\r\n                chapter = part\r\n\r\n        # Extract title (first # heading)\r\n        title_match = re.search(r\'^#\\s+(.+)$\', content, re.MULTILINE)\r\n        title = title_match.group(1) if title_match else file_path.stem\r\n\r\n        # Build URL\r\n        rel_path = file_path.relative_to(file_path.parents[2])  # Relative to docs/\r\n        url = f"/docs/{str(rel_path).replace(\'.md\', \'\').replace(os.sep, \'/\')}"\r\n\r\n        return {\r\n            \'title\': title,\r\n            \'url\': url,\r\n            \'module\': module,\r\n            \'chapter\': chapter,\r\n            \'file_path\': str(file_path)\r\n        }\r\n\r\n    def chunk_document(self, content: str, metadata: Dict, chunk_size: int = 512, overlap: int = 50) -> List[Dict]:\r\n        """Split document into chunks."""\r\n        chunks = []\r\n\r\n        # Split by sections (## headings)\r\n        sections = re.split(r\'\\n##\\s+\', content)\r\n\r\n        for section in sections:\r\n            if not section.strip():\r\n                continue\r\n\r\n            # Split section into paragraphs\r\n            paragraphs = section.split(\'\\n\\n\')\r\n\r\n            current_chunk = []\r\n            current_tokens = 0\r\n\r\n            for para in paragraphs:\r\n                para_tokens = len(para.split())\r\n\r\n                if current_tokens + para_tokens > chunk_size and current_chunk:\r\n                    # Save chunk\r\n                    chunks.append({\r\n                        \'text\': \'\\n\\n\'.join(current_chunk),\r\n                        **metadata,\r\n                        \'chunk_index\': len(chunks)\r\n                    })\r\n\r\n                    # Keep overlap\r\n                    if len(current_chunk) > 1:\r\n                        current_chunk = current_chunk[-1:]\r\n                        current_tokens = len(current_chunk[0].split())\r\n                    else:\r\n                        current_chunk = []\r\n                        current_tokens = 0\r\n\r\n                current_chunk.append(para)\r\n                current_tokens += para_tokens\r\n\r\n            # Add final chunk\r\n            if current_chunk:\r\n                chunks.append({\r\n                    \'text\': \'\\n\\n\'.join(current_chunk),\r\n                    **metadata,\r\n                    \'chunk_index\': len(chunks)\r\n                })\r\n\r\n        return chunks\r\n\r\n    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:\r\n        """Generate embeddings using OpenAI."""\r\n        response = self.openai.embeddings.create(\r\n            model="text-embedding-3-small",\r\n            input=texts\r\n        )\r\n        return [item.embedding for item in response.data]\r\n\r\n    def is_already_ingested(self, content_hash: str) -> bool:\r\n        """Check if document already ingested."""\r\n        cur = self.db.cursor()\r\n        cur.execute(\r\n            "SELECT COUNT(*) FROM documents WHERE content_hash = %s",\r\n            (content_hash,)\r\n        )\r\n        count = cur.fetchone()[0]\r\n        cur.close()\r\n        return count > 0\r\n\r\n    def store_metadata(self, metadata: Dict, content_hash: str, chunk_count: int):\r\n        """Store document metadata in PostgreSQL."""\r\n        cur = self.db.cursor()\r\n        cur.execute(\r\n            """\r\n            INSERT INTO documents (title, url, module, chapter, content_hash, chunk_count)\r\n            VALUES (%s, %s, %s, %s, %s, %s)\r\n            ON CONFLICT (content_hash) DO UPDATE\r\n            SET updated_at = CURRENT_TIMESTAMP\r\n            """,\r\n            (\r\n                metadata[\'title\'],\r\n                metadata[\'url\'],\r\n                metadata[\'module\'],\r\n                metadata[\'chapter\'],\r\n                content_hash,\r\n                chunk_count\r\n            )\r\n        )\r\n        self.db.commit()\r\n        cur.close()\r\n\r\n    def clear_data(self):\r\n        """Clear all data (for reindexing)."""\r\n        # Clear Qdrant\r\n        self.qdrant.delete_collection(self.collection_name)\r\n        self.qdrant.create_collection(\r\n            collection_name=self.collection_name,\r\n            vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\r\n        )\r\n\r\n        # Clear PostgreSQL\r\n        cur = self.db.cursor()\r\n        cur.execute("TRUNCATE TABLE documents RESTART IDENTITY CASCADE")\r\n        self.db.commit()\r\n        cur.close()\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser(description=\'Ingest documentation\')\r\n    parser.add_argument(\'--docs-path\', required=True, help=\'Path to docs directory\')\r\n    parser.add_argument(\'--reindex\', action=\'store_true\', help=\'Clear and reindex\')\r\n\r\n    args = parser.parse_args()\r\n\r\n    ingester = DocumentIngester()\r\n    ingester.ingest_directory(args.docs_path, args.reindex)\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"running-the-api",children:"Running the API"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Development mode (auto-reload)\r\nuvicorn app.main:app --reload --host 0.0.0.0 --port 8000\r\n\r\n# Production mode\r\nuvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4\n"})}),"\n",(0,s.jsx)(e.h2,{id:"testing-the-api",children:"Testing the API"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Health check\r\ncurl http://localhost:8000/health\r\n\r\n# Chat request\r\ncurl -X POST http://localhost:8000/chat \\\r\n  -H "Content-Type: application/json" \\\r\n  -d \'{\r\n    "query": "How do I create a ROS 2 publisher?",\r\n    "top_k": 5\r\n  }\'\r\n\r\n# With session\r\ncurl -X POST http://localhost:8000/chat \\\r\n  -H "Content-Type: application/json" \\\r\n  -d \'{\r\n    "query": "What about subscribers?",\r\n    "session_id": "550e8400-e29b-41d4-a716-446655440000"\r\n  }\'\n'})}),"\n",(0,s.jsx)(e.h2,{id:"docker-deployment",children:"Docker Deployment"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-dockerfile",children:'# Dockerfile\r\nFROM python:3.11-slim\r\n\r\nWORKDIR /app\r\n\r\n# Install dependencies\r\nCOPY requirements.txt .\r\nRUN pip install --no-cache-dir -r requirements.txt\r\n\r\n# Copy application\r\nCOPY app/ ./app/\r\nCOPY .env .\r\n\r\n# Expose port\r\nEXPOSE 8000\r\n\r\n# Run application\r\nCMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]\n'})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-yaml",children:'# docker-compose.yml\r\nversion: \'3.8\'\r\n\r\nservices:\r\n  chatbot-api:\r\n    build: .\r\n    ports:\r\n      - "8000:8000"\r\n    environment:\r\n      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\r\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\r\n      - QDRANT_URL=${QDRANT_URL}\r\n      - QDRANT_API_KEY=${QDRANT_API_KEY}\r\n      - DATABASE_URL=${DATABASE_URL}\r\n    restart: unless-stopped\r\n\r\n  redis:\r\n    image: redis:7-alpine\r\n    ports:\r\n      - "6379:6379"\r\n    restart: unless-stopped\n'})}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Test locally"}),": Ingest documentation and test queries"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Deploy"}),": Follow ",(0,s.jsx)(e.a,{href:"/docs/rag-chatbot/deployment",children:"deployment.md"})," for production"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Integrate"}),": Add chat widget to Docusaurus (see ",(0,s.jsx)(e.a,{href:"integration.md",children:"integration.md"}),")"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Monitor"}),": Set up analytics and logging"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(e.h3,{id:"issue-database-connection-fails",children:"Issue: Database connection fails"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Test connection\r\npython -c \"import psycopg2; psycopg2.connect('$DATABASE_URL'); print('\u2713 Connected')\"\n"})}),"\n",(0,s.jsx)(e.h3,{id:"issue-qdrant-connection-timeout",children:"Issue: Qdrant connection timeout"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Verify API key and URL\r\npython -c \"from qdrant_client import QdrantClient; client = QdrantClient(url='$QDRANT_URL', api_key='$QDRANT_API_KEY'); print(client.get_collections())\"\n"})}),"\n",(0,s.jsx)(e.h3,{id:"issue-embeddings-failing",children:"Issue: Embeddings failing"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Test OpenAI API\r\npython -c \"from openai import OpenAI; client = OpenAI(); print(client.embeddings.create(model='text-embedding-3-small', input=['test']))\"\n"})}),"\n",(0,s.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://qdrant.tech/documentation/quick-start/",children:"Qdrant Setup"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://neon.tech/docs/get-started-with-neon/signing-up",children:"Neon PostgreSQL"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://fastapi.tiangolo.com/deployment/",children:"FastAPI Deployment"})}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(l,{...n})}):l(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>a,x:()=>o});var t=r(6540);const s={},i=t.createContext(s);function a(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),t.createElement(i.Provider,{value:e},n.children)}}}]);