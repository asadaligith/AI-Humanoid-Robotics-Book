"use strict";(self.webpackChunkai_humanoid_robotics_book=self.webpackChunkai_humanoid_robotics_book||[]).push([[1612],{8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>c});var i=s(6540);const r={},t=i.createContext(r);function o(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(t.Provider,{value:n},e.children)}},9708:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"modules/module-05-capstone/chapter-05-simulation-deployment","title":"Chapter 5: Simulation Deployment & Testing","description":"Learning Objectives","source":"@site/docs/modules/module-05-capstone/chapter-05-simulation-deployment.md","sourceDirName":"modules/module-05-capstone","slug":"/modules/module-05-capstone/chapter-05-simulation-deployment","permalink":"/AI-Humanoid-Robotics-Book/docs/modules/module-05-capstone/chapter-05-simulation-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/tree/main/docs/modules/module-05-capstone/chapter-05-simulation-deployment.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"4\ufe0f\u20e3 Manipulation","permalink":"/AI-Humanoid-Robotics-Book/docs/modules/module-05-capstone/chapter-04-manipulation"},"next":{"title":"6\ufe0f\u20e3 Jetson Hardware Deployment","permalink":"/AI-Humanoid-Robotics-Book/docs/modules/module-05-capstone/chapter-06-jetson-deployment"}}');var r=s(4848),t=s(8453);const o={sidebar_position:5},c="Chapter 5: Simulation Deployment & Testing",l={},a=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Gazebo Fortress Deployment",id:"gazebo-fortress-deployment",level:2},{value:"Environment Setup",id:"environment-setup",level:3},{value:"Launch File Configuration",id:"launch-file-configuration",level:3},{value:"Expected Behavior",id:"expected-behavior",level:3},{value:"Isaac Sim Deployment",id:"isaac-sim-deployment",level:2},{value:"USD Scene Setup",id:"usd-scene-setup",level:3},{value:"Isaac Sim Launch File",id:"isaac-sim-launch-file",level:3},{value:"Debugging Multi-Node Systems",id:"debugging-multi-node-systems",level:2},{value:"ROS 2 Introspection Tools",id:"ros-2-introspection-tools",level:3},{value:"Common Integration Issues &amp; Debugging",id:"common-integration-issues--debugging",level:3},{value:"Logging Best Practices",id:"logging-best-practices",level:3},{value:"Performance Metrics",id:"performance-metrics",level:2},{value:"Success Rate Measurement",id:"success-rate-measurement",level:3},{value:"Latency Breakdown",id:"latency-breakdown",level:3},{value:"Research &amp; Evidence",id:"research--evidence",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-5-simulation-deployment--testing",children:"Chapter 5: Simulation Deployment & Testing"})}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.p,{children:["\ud83c\udfaf ",(0,r.jsx)(n.strong,{children:"Deploy"})," complete autonomous systems in Gazebo Fortress and Isaac Sim environments"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83c\udfaf ",(0,r.jsx)(n.strong,{children:"Configure"})," multi-node ROS 2 launch files for complex system orchestration"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83c\udfaf ",(0,r.jsx)(n.strong,{children:"Debug"})," integration issues using ROS 2 introspection tools (rqt_graph, topic echo, logs)"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83c\udfaf ",(0,r.jsx)(n.strong,{children:"Validate"})," end-to-end behavior against acceptance criteria (\u226560% success rate)"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Completed Chapters 1-4 (Architecture, Voice/LLM, Navigation/Perception, Manipulation)"}),"\n",(0,r.jsx)(n.li,{children:"Gazebo Fortress installed OR Isaac Sim 2023.1+ with NVIDIA GPU"}),"\n",(0,r.jsx)(n.li,{children:"All ROS 2 nodes from previous chapters implemented"}),"\n",(0,r.jsx)(n.li,{children:"Simulation assets (URDF, worlds) prepared"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"Simulation is the proving ground for autonomous systems. Before deploying to expensive hardware, we validate the complete integration in virtual environments that perfectly model physics, sensors, and robot dynamics. This chapter guides you through deploying the voice-commanded fetch-and-deliver system in both Gazebo (accessible to all) and Isaac Sim (GPU-accelerated photorealism)."}),"\n",(0,r.jsx)(n.p,{children:"You'll learn how to orchestrate 5+ ROS 2 nodes with launch files, configure simulation parameters for realistic behavior, and systematically debug issues that arise when integrating independently-developed components."}),"\n",(0,r.jsx)(n.h2,{id:"gazebo-fortress-deployment",children:"Gazebo Fortress Deployment"}),"\n",(0,r.jsx)(n.h3,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,r.jsx)(n.p,{children:"The kitchen environment contains:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robot spawn location"}),": (0, 0, 0) facing +X"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Kitchen table"}),": (3, 2, 0.7) with target objects (cups, mugs, plates)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"User location"}),": (-1, 0, 0.5) for object delivery"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Obstacles"}),": Chairs, cabinets, simulated walls for navigation testing"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"World File"}),": ",(0,r.jsx)(n.code,{children:"assets/worlds/kitchen_env.world"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<sdf version="1.6">\n  <world name="kitchen">\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    <include>\n      <uri>model://sun</uri>\n    </include>\n\n    \x3c!-- Kitchen table with objects --\x3e\n    <model name="kitchen_table">\n      <pose>3 2 0 0 0 0</pose>\n      <include>\n        <uri>model://table</uri>\n      </include>\n    </model>\n\n    \x3c!-- Target object: Red cup --\x3e\n    <model name="red_cup">\n      <pose>3.2 2.1 0.75 0 0 0</pose>\n      <include>\n        <uri>model://cup</uri>\n      </include>\n    </model>\n\n    \x3c!-- Obstacles for navigation testing --\x3e\n    <model name="chair_1">\n      <pose>2.5 1.5 0 0 0 1.57</pose>\n      <include>\n        <uri>model://chair</uri>\n      </include>\n    </model>\n  </world>\n</sdf>\n'})}),"\n",(0,r.jsx)(n.h3,{id:"launch-file-configuration",children:"Launch File Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Orchestrate all 5 nodes + Gazebo + robot state publisher:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"File"}),": ",(0,r.jsx)(n.code,{children:"examples/module-05-capstone/launch/gazebo_demo.launch.py"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import IncludeLaunchDescription, ExecuteProcess\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch_ros.actions import Node\nimport os\n\ndef generate_launch_description():\n    # Paths\n    world_file = os.path.join('assets', 'worlds', 'kitchen_env.world')\n    urdf_file = os.path.join('assets', 'urdf', 'unitree_g1.urdf')\n\n    return LaunchDescription([\n        # Launch Gazebo with kitchen world\n        ExecuteProcess(\n            cmd=['gazebo', '--verbose', world_file],\n            output='screen'\n        ),\n\n        # Spawn robot in Gazebo\n        Node(\n            package='gazebo_ros',\n            executable='spawn_entity.py',\n            arguments=['-entity', 'unitree_g1', '-file', urdf_file],\n            output='screen'\n        ),\n\n        # Robot state publisher (TF tree)\n        Node(\n            package='robot_state_publisher',\n            executable='robot_state_publisher',\n            parameters=[{'robot_description': open(urdf_file).read()}],\n            output='screen'\n        ),\n\n        # Voice input node\n        Node(\n            package='capstone_demo',\n            executable='voice_input_node',\n            parameters=[{'whisper_model': 'base'}],\n            output='screen'\n        ),\n\n        # LLM planner node\n        Node(\n            package='capstone_demo',\n            executable='llm_planner_node',\n            output='screen'\n        ),\n\n        # Navigation controller\n        Node(\n            package='capstone_demo',\n            executable='navigation_controller',\n            output='screen'\n        ),\n\n        # Object detection node\n        Node(\n            package='capstone_demo',\n            executable='object_detection_node',\n            output='screen'\n        ),\n\n        # Manipulation controller\n        Node(\n            package='capstone_demo',\n            executable='manipulation_controller',\n            output='screen'\n        ),\n\n        # Integration state machine\n        Node(\n            package='capstone_demo',\n            executable='integration_demo',\n            output='screen'\n        ),\n    ])\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Running the Demo"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"$ source /opt/ros/humble/setup.bash\n$ ros2 launch capstone_demo gazebo_demo.launch.py\n"})}),"\n",(0,r.jsx)(n.h3,{id:"expected-behavior",children:"Expected Behavior"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+0s"}),": Gazebo window opens, robot spawns at origin"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+5s"}),": All nodes initialized, state machine enters IDLE state"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+10s"}),': User speaks command: "Bring me the red cup from the table"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+13s"}),": Transcription complete, LLM generates plan (5-8 actions)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+18s"}),": Robot navigates to table (3m distance, ~10 seconds)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+30s"}),": Object detection identifies red cup, computes 3D pose"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+35s"}),": Manipulation picks cup (grasp planning 3-5 seconds)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+40s"}),": Return navigation to user location"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"T+50s"}),": Place object, task COMPLETED"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Success"}),": Robot delivers cup to user without collisions\n",(0,r.jsx)(n.strong,{children:"Acceptable Failures"})," (per AC-001): 40% failure rate acceptable (navigation blocked, object not found, grasp failure)"]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-sim-deployment",children:"Isaac Sim Deployment"}),"\n",(0,r.jsx)(n.h3,{id:"usd-scene-setup",children:"USD Scene Setup"}),"\n",(0,r.jsx)(n.p,{children:"Isaac Sim uses USD (Universal Scene Description) for photorealistic environments:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"File"}),": ",(0,r.jsx)(n.code,{children:"assets/usd/kitchen_env.usd"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Create USD scene with Isaac Sim\nfrom pxr import Usd, UsdGeom, UsdPhysics\n\nstage = Usd.Stage.CreateNew('kitchen_env.usd')\n\n# Add kitchen table\ntable_prim = stage.DefinePrim('/World/KitchenTable', 'Xform')\ntable_prim.GetAttribute('xformOp:translate').Set((3.0, 2.0, 0.7))\n\n# Add physics materials for realistic interaction\nUsdPhysics.Scene.Define(stage, '/World/PhysicsScene')\n"})}),"\n",(0,r.jsx)(n.p,{children:"Full scene created in Isaac Sim GUI, exported to USD."}),"\n",(0,r.jsx)(n.h3,{id:"isaac-sim-launch-file",children:"Isaac Sim Launch File"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# launch/isaac_demo.launch.py\nreturn LaunchDescription([\n    # Launch Isaac Sim with ROS 2 bridge\n    ExecuteProcess(\n        cmd=['python', 'scripts/isaac_sim_launcher.py', '--usd', 'assets/usd/kitchen_env.usd'],\n        output='screen'\n    ),\n\n    # Same ROS 2 nodes as Gazebo (nodes are simulator-agnostic!)\n    # ... (identical node definitions)\n])\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Advantage"}),": Same ROS 2 nodes work in both simulators\u2014only simulation backend changes."]}),"\n",(0,r.jsx)(n.h2,{id:"debugging-multi-node-systems",children:"Debugging Multi-Node Systems"}),"\n",(0,r.jsx)(n.h3,{id:"ros-2-introspection-tools",children:"ROS 2 Introspection Tools"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"1. Node Graph Visualization"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"$ rqt_graph\n"})}),"\n",(0,r.jsx)(n.p,{children:"Verify all nodes are running and topics are connected correctly."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"2. Topic Monitoring"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"$ ros2 topic echo /voice/transcribed_text\n$ ros2 topic hz /camera/image_raw  # Check camera publishing at 30 Hz\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"3. Service Introspection"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'$ ros2 service list\n$ ros2 service call /planning/validate_plan custom_srvs/ValidatePlan "{plan: ...}"\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"4. Action Status"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"$ ros2 action list\n$ ros2 action info /navigation/navigate_to_pose\n"})}),"\n",(0,r.jsx)(n.h3,{id:"common-integration-issues--debugging",children:"Common Integration Issues & Debugging"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Issue 1: Voice Node Not Publishing Transcriptions"})}),"\n",(0,r.jsx)(n.p,{children:"Symptom:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[ERROR] [voice_input_node]: No voice activity detected\n"})}),"\n",(0,r.jsx)(n.p,{children:"Debug Steps:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check microphone device\n$ arecord -l\n\n# Test audio capture\n$ arecord -d 3 test.wav && aplay test.wav\n\n# Monitor voice topic\n$ ros2 topic hz /voice/transcribed_text  # Should be >0 Hz when speaking\n"})}),"\n",(0,r.jsx)(n.p,{children:"Solution:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ensure ",(0,r.jsx)(n.code,{children:"--device=/dev/snd:/dev/snd"})," in Docker run command"]}),"\n",(0,r.jsxs)(n.li,{children:["Lower ",(0,r.jsx)(n.code,{children:"silence_threshold"})," in ",(0,r.jsx)(n.code,{children:"voice_config.yaml"})," from 0.01 to 0.005"]}),"\n",(0,r.jsxs)(n.li,{children:["Verify Whisper model downloaded: ",(0,r.jsx)(n.code,{children:"~/.cache/whisper/base.pt"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Issue 2: LLM Planning Timeout"})}),"\n",(0,r.jsx)(n.p,{children:"Symptom:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[ERROR] [llm_planner_node]: Request to OpenAI API timed out after 30s\n[WARN] [integration_demo]: State stuck in PLANNING\n"})}),"\n",(0,r.jsx)(n.p,{children:"Debug Steps:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Verify API key\n$ echo $OPENAI_API_KEY  # Should start with sk-proj-...\n\n# Test API connectivity\n$ curl https://api.openai.com/v1/models -H "Authorization: Bearer $OPENAI_API_KEY"\n\n# Monitor LLM output\n$ ros2 topic echo /llm/action_sequence\n'})}),"\n",(0,r.jsx)(n.p,{children:"Solution:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Set environment variable: ",(0,r.jsx)(n.code,{children:'export OPENAI_API_KEY="sk-proj-..."'})]}),"\n",(0,r.jsx)(n.li,{children:"Check internet connection and firewall rules"}),"\n",(0,r.jsxs)(n.li,{children:["Enable mock_llm mode for offline testing: ",(0,r.jsx)(n.code,{children:"mock_llm:=true"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Issue 3: Navigation Aborted (No Valid Path)"})}),"\n",(0,r.jsx)(n.p,{children:"Symptom:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[ERROR] [navigation_controller]: Nav2 goal aborted - PLANNING_FAILED\n[ERROR] [integration_demo]: Navigation failed: No valid path found\n"})}),"\n",(0,r.jsx)(n.p,{children:"Debug Steps:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Visualize costmap\n$ ros2 run rviz2 rviz2 -d config/nav2.rviz\n\n# Check obstacle inflation\n$ ros2 param get /local_costmap/local_costmap inflation_radius\n# If >0.5m, may be too conservative\n\n# Verify map-odom transform\n$ ros2 run tf2_tools view_frames\n$ evince frames.pdf  # Check map\u2192odom\u2192base_link chain\n"})}),"\n",(0,r.jsx)(n.p,{children:"Solution:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Reduce ",(0,r.jsx)(n.code,{children:"inflation_radius"})," in ",(0,r.jsx)(n.code,{children:"nav2_params.yaml"})," from 0.55m to 0.35m"]}),"\n",(0,r.jsxs)(n.li,{children:["Lower ",(0,r.jsx)(n.code,{children:"cost_scaling_factor"})," from 3.0 to 2.0"]}),"\n",(0,r.jsxs)(n.li,{children:["Re-localize robot: publish to ",(0,r.jsx)(n.code,{children:"/initialpose"})," topic"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Issue 4: Object Detection Returns No Results"})}),"\n",(0,r.jsx)(n.p,{children:"Symptom:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[WARN] [object_detection_node]: No objects detected in frame (confidence >0.6)\n[ERROR] [integration_demo]: Detection failed after 3 retries\n"})}),"\n",(0,r.jsx)(n.p,{children:"Debug Steps:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# View camera feed\n$ ros2 run rqt_image_view rqt_image_view /camera/image_raw\n\n# Check detection output\n$ ros2 topic echo /perception/detections\n\n# View annotated detections\n$ ros2 run rqt_image_view rqt_image_view /perception/annotated_image\n"})}),"\n",(0,r.jsx)(n.p,{children:"Solution:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Lower ",(0,r.jsx)(n.code,{children:"confidence_threshold"})," from 0.6 to 0.5 in detection node params"]}),"\n",(0,r.jsxs)(n.li,{children:["Check YOLO model loaded: verify ",(0,r.jsx)(n.code,{children:"yolov8n.pt"})," exists"]}),"\n",(0,r.jsx)(n.li,{children:"Improve lighting in Gazebo: add more light sources to world file"}),"\n",(0,r.jsxs)(n.li,{children:["Use larger YOLO model: ",(0,r.jsx)(n.code,{children:"yolov8s.pt"})," instead of ",(0,r.jsx)(n.code,{children:"yolov8n.pt"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Issue 5: Grasp Execution Fails (IK Solution Not Found)"})}),"\n",(0,r.jsx)(n.p,{children:"Symptom:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[ERROR] [manipulation_controller]: IK solver failed for target pose\n[ERROR] [manipulation_controller]: Pick failed after 3 attempts\n"})}),"\n",(0,r.jsx)(n.p,{children:"Debug Steps:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check gripper joint limits\n$ ros2 param list /manipulation_controller\n\n# View robot model in RViz\n$ ros2 launch urdf_tutorial display.launch.py model:=assets/urdf/unitree_g1.urdf\n\n# Monitor manipulation status\n$ ros2 topic echo /manipulation/status\n"})}),"\n",(0,r.jsx)(n.p,{children:"Solution:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Increase ",(0,r.jsx)(n.code,{children:"pre_grasp_offset"})," in ",(0,r.jsx)(n.code,{children:"grasp_poses.yaml"})," from 0.10m to 0.15m"]}),"\n",(0,r.jsx)(n.li,{children:"Verify object pose is within reachable workspace (0.2m to 0.8m from base)"}),"\n",(0,r.jsxs)(n.li,{children:["Simplify IK solver settings: reduce ",(0,r.jsx)(n.code,{children:"max_ik_iterations"})," in MoveIt config"]}),"\n",(0,r.jsx)(n.li,{children:"Use predefined grasps instead of heuristic planning"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Issue 6: System Freezes in AWAITING_CLARIFICATION State"})}),"\n",(0,r.jsx)(n.p,{children:"Symptom:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[WARN] [integration_demo]: Requesting clarification: Could not detect mug\n[INFO] [integration_demo]: State: AWAITING_CLARIFICATION\n"})}),"\n",(0,r.jsx)(n.p,{children:"Debug Steps:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check clarification topic\n$ ros2 topic echo /llm/clarification_request\n\n# Manually provide response\n$ ros2 topic pub /voice/transcribed_text std_msgs/String \"{data: 'The blue mug on the left'}\"\n"})}),"\n",(0,r.jsx)(n.p,{children:"Solution:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Implement timeout for clarification (30s default)"}),"\n",(0,r.jsx)(n.li,{children:"Add fallback behavior: retry with relaxed constraints after timeout"}),"\n",(0,r.jsxs)(n.li,{children:["Enable mock mode to bypass clarification: ",(0,r.jsx)(n.code,{children:"test_mode:=true"})]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"logging-best-practices",children:"Logging Best Practices"}),"\n",(0,r.jsx)(n.p,{children:"Use ROS 2 logger with severity levels:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"self.get_logger().debug('Processing voice command')  # Development\nself.get_logger().info('Transcribed: \"Bring me cup\"')  # Normal operation\nself.get_logger().warn('Navigation retry attempt 2/3')  # Recoverable issues\nself.get_logger().error('Plan validation failed')  # Errors requiring attention\nself.get_logger().fatal('Critical sensor failure')  # Unrecoverable\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Viewing Logs"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"$ ros2 log level set /voice_input_node debug\n$ ros2 log view\n"})}),"\n",(0,r.jsx)(n.h2,{id:"performance-metrics",children:"Performance Metrics"}),"\n",(0,r.jsx)(n.h3,{id:"success-rate-measurement",children:"Success Rate Measurement"}),"\n",(0,r.jsx)(n.p,{children:"Run 20 trials with different commands and object placements:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"$ python scripts/testing/benchmark_capstone.py --trials 20\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected Results"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Success Rate"}),": \u226560% (per AC-001)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mean End-to-End Latency"}),": <60 seconds (voice \u2192 delivery)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Navigation Success"}),": \u226590% (when path exists)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Detection Accuracy"}),": \u226585% (for known objects)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Grasp Success"}),": \u226570% (for graspable objects)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"latency-breakdown",children:"Latency Breakdown"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Phase"}),(0,r.jsx)(n.th,{children:"Target (seconds)"}),(0,r.jsx)(n.th,{children:"Typical Range"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Voice Transcription"}),(0,r.jsx)(n.td,{children:"<3"}),(0,r.jsx)(n.td,{children:"2-4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"LLM Planning"}),(0,r.jsx)(n.td,{children:"<10"}),(0,r.jsx)(n.td,{children:"5-15"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Navigation (3m)"}),(0,r.jsx)(n.td,{children:"<15"}),(0,r.jsx)(n.td,{children:"10-20"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Object Detection"}),(0,r.jsx)(n.td,{children:"<2"}),(0,r.jsx)(n.td,{children:"1-3"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Grasp Planning"}),(0,r.jsx)(n.td,{children:"<5"}),(0,r.jsx)(n.td,{children:"3-7"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Return Navigation"}),(0,r.jsx)(n.td,{children:"<15"}),(0,r.jsx)(n.td,{children:"10-20"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Total"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"<50"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"31-69"})})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"research--evidence",children:"Research & Evidence"}),"\n",(0,r.jsx)(n.p,{children:"Simulation-based validation methodologies informed by:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Gazebo Best Practices: ",(0,r.jsx)(n.a,{href:"https://gazebosim.org/docs",children:"Open Robotics Documentation"})]}),"\n",(0,r.jsxs)(n.li,{children:["Isaac Sim ROS 2 Integration: ",(0,r.jsx)(n.a,{href:"https://nvidia-isaac-ros.github.io/",children:"NVIDIA Isaac ROS"})]}),"\n",(0,r.jsxs)(n.li,{children:["Benchmarking Robotics Systems: ",(0,r.jsx)(n.a,{href:"https://ieeexplore.ieee.org/",children:"IEEE Robotics Benchmarking Standards"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"Simulation deployment transforms individual components into a validated autonomous system:"}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Launch files"})," orchestrate multi-node systems with proper sequencing and parameter passing"]}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Dual simulator support"})," (Gazebo + Isaac Sim) maximizes accessibility while enabling photorealism"]}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Systematic debugging"})," using ROS 2 introspection tools accelerates integration troubleshooting"]}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Performance benchmarking"})," provides quantitative validation against acceptance criteria"]}),"\n",(0,r.jsx)(n.p,{children:"With the system running successfully in simulation, you're ready to deploy to physical hardware."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Next"}),": ",(0,r.jsx)(n.a,{href:"/AI-Humanoid-Robotics-Book/docs/modules/module-05-capstone/chapter-06-jetson-deployment",children:"Chapter 6: Jetson Hardware Deployment"})," packages the system for embedded edge AI platforms."]}),"\n",(0,r.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsxs)(n.p,{children:["\u2b50 ",(0,r.jsx)(n.strong,{children:"Exercise 1"}),": Record a rosbag of a successful fetch-and-deliver run. Replay it and verify all topics publish identical data."]}),"\n",(0,r.jsxs)(n.p,{children:["\u2b50\u2b50 ",(0,r.jsx)(n.strong,{children:"Exercise 2"}),": Implement a ",(0,r.jsx)(n.strong,{children:"failure injection node"})," that randomly blocks navigation paths or hides objects. Measure system robustness (recovery rate)."]}),"\n",(0,r.jsxs)(n.p,{children:["\u2b50\u2b50\u2b50 ",(0,r.jsx)(n.strong,{children:"Exercise 3"}),": Compare Gazebo vs Isaac Sim performance: latency, detection accuracy, physics realism. Document tradeoffs for hardware deployment decisions."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Word Count"}),": 334 words (Target: 300-350) \u2705"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);