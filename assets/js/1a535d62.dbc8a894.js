"use strict";(self.webpackChunkai_humanoid_robotics_book=self.webpackChunkai_humanoid_robotics_book||[]).push([[3258],{889:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"rag-chatbot/architecture","title":"RAG Chatbot Architecture","description":"Overview","source":"@site/docs/rag-chatbot/architecture.md","sourceDirName":"rag-chatbot","slug":"/rag-chatbot/architecture","permalink":"/docs/rag-chatbot/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/tree/main/docs/rag-chatbot/architecture.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chatbot User Guide","permalink":"/docs/rag-chatbot/user-guide"},"next":{"title":"RAG Chatbot Setup Guide","permalink":"/docs/rag-chatbot/setup"}}');var s=r(4848),i=r(8453);const o={},a="RAG Chatbot Architecture",c={},l=[{value:"Overview",id:"overview",level:2},{value:"\u2728 New Features",id:"-new-features",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Component Details",id:"component-details",level:2},{value:"1. Document Ingestion Pipeline",id:"1-document-ingestion-pipeline",level:3},{value:"2. Query Processing",id:"2-query-processing",level:3},{value:"3. Response Generation",id:"3-response-generation",level:3},{value:"4. FastAPI Application",id:"4-fastapi-application",level:3},{value:"Database Schema (PostgreSQL)",id:"database-schema-postgresql",level:2},{value:"Qdrant Collection Schema",id:"qdrant-collection-schema",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"1. Caching Strategy",id:"1-caching-strategy",level:3},{value:"2. Rate Limiting",id:"2-rate-limiting",level:3},{value:"3. Cost Optimization",id:"3-cost-optimization",level:3},{value:"4. Scalability",id:"4-scalability",level:3},{value:"Security",id:"security",level:2},{value:"Monitoring &amp; Analytics",id:"monitoring--analytics",level:2},{value:"Deployment",id:"deployment",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"rag-chatbot-architecture",children:"RAG Chatbot Architecture"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The Retrieval-Augmented Generation (RAG) chatbot provides intelligent, context-aware assistance for the AI & Humanoid Robotics course. It combines vector search, PostgreSQL metadata storage, and Claude's language understanding to answer student questions."}),"\n",(0,s.jsx)(n.h2,{id:"-new-features",children:"\u2728 New Features"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Enhanced Conversational AI"})," (Latest Update):"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Greeting Support"}),': Responds naturally to casual greetings ("hi", "hello", "hey", etc.)']}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Improved Answer Quality"}),": Resolved response generation issues - now provides accurate, comprehensive answers"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Full Book Integration"}),": All 32 chapters from 5 modules ingested into RAG system"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Context-Aware Responses"}),": Understands course structure and provides relevant module references"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Interactive Learning"}),": Asks clarifying questions when user intent is ambiguous"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                     User Interface                           \u2502\r\n\u2502              (Web Chat Widget + CLI)                         \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n                      \u2502\r\n                      \u2193\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                   API Gateway (FastAPI)                      \u2502\r\n\u2502  - Request validation                                        \u2502\r\n\u2502  - Rate limiting                                             \u2502\r\n\u2502  - Authentication                                            \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n                      \u2502\r\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n        \u2193                           \u2193\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  Query Processor  \u2502       \u2502 Session Manager  \u2502\r\n\u2502  - Intent detect  \u2502       \u2502 - User history   \u2502\r\n\u2502  - Query rewrite  \u2502       \u2502 - Context cache  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n          \u2502\r\n          \u2193\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              Embedding & Retrieval Pipeline                  \u2502\r\n\u2502                                                              \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502  \u2502  Embeddings  \u2502\u2500\u2500\u2500\u2192\u2502   Qdrant     \u2502\u2500\u2500\u2500\u2192\u2502  Reranking   \u2502  \u2502\r\n\u2502  \u2502  (OpenAI)    \u2502    \u2502 Vector Store \u2502    \u2502  (Optional)  \u2502  \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n                      \u2502\r\n                      \u2193\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                PostgreSQL (Neon)                             \u2502\r\n\u2502  - Document metadata                                         \u2502\r\n\u2502  - User sessions                                             \u2502\r\n\u2502  - Feedback tracking                                         \u2502\r\n\u2502  - Analytics                                                 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n                      \u2502\r\n                      \u2193\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              Claude API (Response Generation)                \u2502\r\n\u2502  - Context: Retrieved docs                                   \u2502\r\n\u2502  - System: Course assistant persona                          \u2502\r\n\u2502  - Tools: Code execution, navigation                         \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n                      \u2502\r\n                      \u2193\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                     Response                                 \u2502\r\n\u2502  - Formatted answer                                          \u2502\r\n\u2502  - Source citations                                          \u2502\r\n\u2502  - Suggested next steps                                      \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"component-details",children:"Component Details"}),"\n",(0,s.jsx)(n.h3,{id:"1-document-ingestion-pipeline",children:"1. Document Ingestion Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"""\r\nIngests course content into vector database\r\n"""\r\n\r\nclass DocumentIngestionPipeline:\r\n    def __init__(self, qdrant_client, postgres_conn, openai_api_key):\r\n        self.qdrant = qdrant_client\r\n        self.db = postgres_conn\r\n        self.embeddings = OpenAIEmbeddings(api_key=openai_api_key)\r\n\r\n    def ingest_directory(self, docs_path: str):\r\n        """Ingest all markdown files from documentation."""\r\n        documents = []\r\n\r\n        for md_file in Path(docs_path).rglob("*.md"):\r\n            # Parse markdown\r\n            content = md_file.read_text()\r\n            metadata = self.extract_metadata(md_file, content)\r\n\r\n            # Chunk document\r\n            chunks = self.chunk_document(content, metadata)\r\n            documents.extend(chunks)\r\n\r\n        # Generate embeddings\r\n        embeddings = self.embeddings.embed_documents([d[\'text\'] for d in documents])\r\n\r\n        # Store in Qdrant\r\n        self.qdrant.upsert(\r\n            collection_name="course_docs",\r\n            points=[\r\n                {\r\n                    "id": i,\r\n                    "vector": emb,\r\n                    "payload": doc\r\n                }\r\n                for i, (emb, doc) in enumerate(zip(embeddings, documents))\r\n            ]\r\n        )\r\n\r\n        # Store metadata in PostgreSQL\r\n        self.db.execute_many(\r\n            "INSERT INTO documents (id, title, url, module, chapter) VALUES (%s, %s, %s, %s, %s)",\r\n            [(d[\'id\'], d[\'title\'], d[\'url\'], d[\'module\'], d[\'chapter\']) for d in documents]\r\n        )\r\n\r\n    def chunk_document(self, content: str, metadata: dict, chunk_size=512, overlap=50):\r\n        """Split document into overlapping chunks."""\r\n        chunks = []\r\n        sentences = content.split(\'\\n\\n\')  # Split by paragraphs\r\n\r\n        current_chunk = []\r\n        current_size = 0\r\n\r\n        for sentence in sentences:\r\n            tokens = len(sentence.split())\r\n\r\n            if current_size + tokens > chunk_size and current_chunk:\r\n                # Save chunk\r\n                chunks.append({\r\n                    \'text\': \'\\n\\n\'.join(current_chunk),\r\n                    **metadata,\r\n                    \'chunk_index\': len(chunks)\r\n                })\r\n\r\n                # Keep overlap\r\n                overlap_size = 0\r\n                overlap_chunk = []\r\n                for s in reversed(current_chunk):\r\n                    overlap_size += len(s.split())\r\n                    overlap_chunk.insert(0, s)\r\n                    if overlap_size >= overlap:\r\n                        break\r\n\r\n                current_chunk = overlap_chunk\r\n                current_size = overlap_size\r\n\r\n            current_chunk.append(sentence)\r\n            current_size += tokens\r\n\r\n        # Add final chunk\r\n        if current_chunk:\r\n            chunks.append({\r\n                \'text\': \'\\n\\n\'.join(current_chunk),\r\n                **metadata,\r\n                \'chunk_index\': len(chunks)\r\n            })\r\n\r\n        return chunks\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-query-processing",children:"2. Query Processing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"""\r\nProcesses user queries and retrieves relevant context\r\n"""\r\n\r\nclass QueryProcessor:\r\n    def __init__(self, qdrant_client, embeddings):\r\n        self.qdrant = qdrant_client\r\n        self.embeddings = embeddings\r\n\r\n    def process_query(self, query: str, filters: dict = None, top_k: int = 5):\r\n        """Process query and retrieve relevant documents."""\r\n\r\n        # Generate query embedding\r\n        query_embedding = self.embeddings.embed_query(query)\r\n\r\n        # Search Qdrant\r\n        search_results = self.qdrant.search(\r\n            collection_name="course_docs",\r\n            query_vector=query_embedding,\r\n            limit=top_k,\r\n            query_filter=self.build_filter(filters) if filters else None\r\n        )\r\n\r\n        # Extract contexts\r\n        contexts = []\r\n        for result in search_results:\r\n            contexts.append({\r\n                \'text\': result.payload[\'text\'],\r\n                \'score\': result.score,\r\n                \'metadata\': {\r\n                    \'title\': result.payload[\'title\'],\r\n                    \'url\': result.payload[\'url\'],\r\n                    \'module\': result.payload.get(\'module\'),\r\n                    \'chapter\': result.payload.get(\'chapter\'),\r\n                }\r\n            })\r\n\r\n        return contexts\r\n\r\n    def build_filter(self, filters: dict):\r\n        """Build Qdrant filter from dict."""\r\n        conditions = []\r\n\r\n        for key, value in filters.items():\r\n            conditions.append({\r\n                "key": key,\r\n                "match": {"value": value}\r\n            })\r\n\r\n        return {"must": conditions} if conditions else None\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-response-generation",children:"3. Response Generation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"""\r\nGenerates responses using Claude with retrieved context\r\n"""\r\n\r\nimport anthropic\r\n\r\nclass ResponseGenerator:\r\n    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-20241022"):\r\n        self.client = anthropic.Anthropic(api_key=api_key)\r\n        self.model = model\r\n\r\n    def generate_response(self, query: str, contexts: list, conversation_history: list = None):\r\n        """Generate response with retrieved context."""\r\n\r\n        # Build context string\r\n        context_str = self.format_contexts(contexts)\r\n\r\n        # System prompt\r\n        system_prompt = f"""You are an intelligent assistant for the AI & Humanoid Robotics course. Help students learn ROS 2, Gazebo, Isaac Sim, and autonomous robotics.\r\n\r\nRetrieved Context:\r\n{context_str}\r\n\r\nGuidelines:\r\n- Answer based on the retrieved context when possible\r\n- Cite sources using [Module X, Chapter Y] notation\r\n- Provide code examples when relevant\r\n- Suggest related topics for deeper learning\r\n- If the question is outside the course scope, politely redirect\r\n- Be encouraging and educational"""\r\n\r\n        # Build message history\r\n        messages = []\r\n        if conversation_history:\r\n            messages.extend(conversation_history)\r\n\r\n        messages.append({\r\n            "role": "user",\r\n            "content": query\r\n        })\r\n\r\n        # Generate response\r\n        response = self.client.messages.create(\r\n            model=self.model,\r\n            max_tokens=2048,\r\n            system=system_prompt,\r\n            messages=messages\r\n        )\r\n\r\n        answer = response.content[0].text\r\n\r\n        # Add source citations\r\n        sources = self.extract_sources(contexts)\r\n\r\n        return {\r\n            \'answer\': answer,\r\n            \'sources\': sources,\r\n            \'contexts_used\': len(contexts)\r\n        }\r\n\r\n    def format_contexts(self, contexts: list) -> str:\r\n        """Format retrieved contexts for prompt."""\r\n        formatted = []\r\n\r\n        for i, ctx in enumerate(contexts, 1):\r\n            meta = ctx[\'metadata\']\r\n            formatted.append(\r\n                f"[Source {i}] {meta.get(\'title\', \'Unknown\')}\\n"\r\n                f"Module: {meta.get(\'module\', \'N/A\')}, Chapter: {meta.get(\'chapter\', \'N/A\')}\\n"\r\n                f"Content: {ctx[\'text\']}\\n"\r\n            )\r\n\r\n        return "\\n".join(formatted)\r\n\r\n    def extract_sources(self, contexts: list) -> list:\r\n        """Extract source references."""\r\n        sources = []\r\n\r\n        for ctx in contexts:\r\n            meta = ctx[\'metadata\']\r\n            sources.append({\r\n                \'title\': meta.get(\'title\'),\r\n                \'url\': meta.get(\'url\'),\r\n                \'module\': meta.get(\'module\'),\r\n                \'chapter\': meta.get(\'chapter\'),\r\n                \'relevance_score\': ctx[\'score\']\r\n            })\r\n\r\n        return sources\n'})}),"\n",(0,s.jsx)(n.h3,{id:"4-fastapi-application",children:"4. FastAPI Application"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"""\r\nAPI endpoints for chatbot\r\n"""\r\n\r\nfrom fastapi import FastAPI, HTTPException, Depends\r\nfrom pydantic import BaseModel\r\nfrom typing import List, Optional\r\nimport uvicorn\r\n\r\napp = FastAPI(title="RAG Chatbot API")\r\n\r\nclass ChatRequest(BaseModel):\r\n    query: str\r\n    session_id: Optional[str] = None\r\n    filters: Optional[dict] = None\r\n    top_k: int = 5\r\n\r\nclass ChatResponse(BaseModel):\r\n    answer: str\r\n    sources: List[dict]\r\n    session_id: str\r\n\r\nclass Chatbot:\r\n    def __init__(self):\r\n        self.query_processor = QueryProcessor(qdrant_client, embeddings)\r\n        self.response_generator = ResponseGenerator(claude_api_key)\r\n        self.session_manager = SessionManager(db_connection)\r\n\r\n    async def process_chat(self, request: ChatRequest) -> ChatResponse:\r\n        """Process chat request."""\r\n\r\n        # Get or create session\r\n        session = self.session_manager.get_or_create(request.session_id)\r\n\r\n        # Retrieve context\r\n        contexts = self.query_processor.process_query(\r\n            request.query,\r\n            filters=request.filters,\r\n            top_k=request.top_k\r\n        )\r\n\r\n        # Generate response\r\n        result = self.response_generator.generate_response(\r\n            request.query,\r\n            contexts,\r\n            conversation_history=session.history\r\n        )\r\n\r\n        # Update session\r\n        session.add_exchange(request.query, result[\'answer\'])\r\n\r\n        # Log to database\r\n        self.log_interaction(session.id, request.query, result)\r\n\r\n        return ChatResponse(\r\n            answer=result[\'answer\'],\r\n            sources=result[\'sources\'],\r\n            session_id=session.id\r\n        )\r\n\r\nchatbot = Chatbot()\r\n\r\n@app.post("/chat", response_model=ChatResponse)\r\nasync def chat(request: ChatRequest):\r\n    """Chat endpoint."""\r\n    try:\r\n        return await chatbot.process_chat(request)\r\n    except Exception as e:\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n@app.get("/health")\r\nasync def health():\r\n    """Health check."""\r\n    return {"status": "healthy"}\r\n\r\nif __name__ == "__main__":\r\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"database-schema-postgresql",children:"Database Schema (PostgreSQL)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Documents metadata\r\nCREATE TABLE documents (\r\n    id SERIAL PRIMARY KEY,\r\n    title VARCHAR(255) NOT NULL,\r\n    url VARCHAR(512),\r\n    module VARCHAR(50),\r\n    chapter VARCHAR(50),\r\n    content_hash VARCHAR(64) UNIQUE,\r\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\r\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Chat sessions\r\nCREATE TABLE chat_sessions (\r\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\r\n    user_id VARCHAR(100),\r\n    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\r\n    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\r\n    message_count INTEGER DEFAULT 0\r\n);\r\n\r\n-- Chat messages\r\nCREATE TABLE chat_messages (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id),\r\n    role VARCHAR(20) NOT NULL,  -- 'user' or 'assistant'\r\n    content TEXT NOT NULL,\r\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Retrieved documents (for analytics)\r\nCREATE TABLE retrieved_documents (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id),\r\n    document_id INTEGER REFERENCES documents(id),\r\n    relevance_score FLOAT,\r\n    query TEXT,\r\n    retrieved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- User feedback\r\nCREATE TABLE feedback (\r\n    id SERIAL PRIMARY KEY,\r\n    session_id UUID REFERENCES chat_sessions(id),\r\n    message_id INTEGER,\r\n    rating INTEGER CHECK (rating BETWEEN 1 AND 5),\r\n    comment TEXT,\r\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n);\r\n\r\n-- Indexes\r\nCREATE INDEX idx_sessions_user ON chat_sessions(user_id);\r\nCREATE INDEX idx_messages_session ON chat_messages(session_id);\r\nCREATE INDEX idx_documents_module ON documents(module);\r\nCREATE INDEX idx_retrieved_query ON retrieved_documents(query);\n"})}),"\n",(0,s.jsx)(n.h2,{id:"qdrant-collection-schema",children:"Qdrant Collection Schema"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from qdrant_client import QdrantClient\r\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\r\n\r\n# Initialize client\r\nclient = QdrantClient(url="https://your-cluster.qdrant.io", api_key="your-key")\r\n\r\n# Create collection\r\nclient.create_collection(\r\n    collection_name="course_docs",\r\n    vectors_config=VectorParams(\r\n        size=1536,  # OpenAI text-embedding-3-small dimension\r\n        distance=Distance.COSINE\r\n    )\r\n)\r\n\r\n# Create payload indexes for filtering\r\nclient.create_payload_index(\r\n    collection_name="course_docs",\r\n    field_name="module",\r\n    field_schema="keyword"\r\n)\r\n\r\nclient.create_payload_index(\r\n    collection_name="course_docs",\r\n    field_name="chapter",\r\n    field_schema="keyword"\r\n)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"1-caching-strategy",children:"1. Caching Strategy"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Cache embeddings for frequently asked questions"}),"\n",(0,s.jsx)(n.li,{children:"Cache Claude responses for identical queries"}),"\n",(0,s.jsx)(n.li,{children:"Use Redis for session management"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-rate-limiting",children:"2. Rate Limiting"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"10 requests/minute per user"}),"\n",(0,s.jsx)(n.li,{children:"1000 requests/day per API key"}),"\n",(0,s.jsx)(n.li,{children:"Exponential backoff on API failures"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"3-cost-optimization",children:"3. Cost Optimization"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use text-embedding-3-small ($0.02/1M tokens) instead of ada-002"}),"\n",(0,s.jsx)(n.li,{children:"Cache common query embeddings"}),"\n",(0,s.jsx)(n.li,{children:"Batch document processing during ingestion"}),"\n",(0,s.jsx)(n.li,{children:"Use Claude 3.5 Sonnet (not Opus) for most queries"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"4-scalability",children:"4. Scalability"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Horizontal scaling with load balancer"}),"\n",(0,s.jsx)(n.li,{children:"Database connection pooling"}),"\n",(0,s.jsx)(n.li,{children:"Async I/O for API calls"}),"\n",(0,s.jsx)(n.li,{children:"Qdrant cluster for large document collections"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"security",children:"Security"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"API Key Management"}),": Store in environment variables, never in code"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input Validation"}),": Sanitize user queries, prevent prompt injection"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Rate Limiting"}),": Prevent abuse and DoS attacks"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Authentication"}),": Optional user authentication for personalized experience"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Privacy"}),": Anonymize logs, respect user data preferences"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"monitoring--analytics",children:"Monitoring & Analytics"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Track key metrics\r\nclass Analytics:\r\n    def track_query(self, session_id, query, response_time, contexts_count):\r\n        """Track query metrics."""\r\n        self.db.execute(\r\n            """\r\n            INSERT INTO query_analytics\r\n            (session_id, query, response_time_ms, contexts_retrieved, timestamp)\r\n            VALUES (%s, %s, %s, %s, NOW())\r\n            """,\r\n            (session_id, query, response_time * 1000, contexts_count)\r\n        )\r\n\r\n    def get_metrics(self, days=7):\r\n        """Get analytics for last N days."""\r\n        return self.db.query(\r\n            """\r\n            SELECT\r\n                DATE(timestamp) as date,\r\n                COUNT(*) as total_queries,\r\n                AVG(response_time_ms) as avg_response_time,\r\n                AVG(contexts_retrieved) as avg_contexts\r\n            FROM query_analytics\r\n            WHERE timestamp >= NOW() - INTERVAL \'%s days\'\r\n            GROUP BY DATE(timestamp)\r\n            ORDER BY date DESC\r\n            """,\r\n            (days,)\r\n        )\n'})}),"\n",(0,s.jsx)(n.h2,{id:"deployment",children:"Deployment"}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"/docs/rag-chatbot/deployment",children:"deployment.md"})," for production deployment instructions."]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Setup"}),": Follow ",(0,s.jsx)(n.a,{href:"/docs/rag-chatbot/setup",children:"setup.md"})," for local development"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Integration"}),": See ",(0,s.jsx)(n.a,{href:"integration.md",children:"integration.md"})," for embedding in Docusaurus"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Customization"}),": Review ",(0,s.jsx)(n.a,{href:"customization.md",children:"customization.md"})," for branding"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://qdrant.tech/documentation/",children:"Qdrant Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://neon.tech/docs",children:"Neon PostgreSQL"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.anthropic.com/",children:"Anthropic Claude API"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://fastapi.tiangolo.com/",children:"FastAPI Documentation"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var t=r(6540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);