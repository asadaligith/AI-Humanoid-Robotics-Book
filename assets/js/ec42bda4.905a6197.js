"use strict";(self.webpackChunkai_humanoid_robotics_book=self.webpackChunkai_humanoid_robotics_book||[]).push([[332],{6078:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"appendices/citations","title":"Citations and References","description":"This page contains all citations referenced throughout the AI Humanoid Robotics Book, organized by module and formatted in APA 7th edition style.","source":"@site/docs/appendices/citations.md","sourceDirName":"appendices","slug":"/appendices/citations","permalink":"/AI-Humanoid-Robotics-Book/docs/appendices/citations","draft":false,"unlisted":false,"editUrl":"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/tree/main/docs/appendices/citations.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4}}');var o=i(4848),t=i(8453);const r={sidebar_position:4},a="Citations and References",c={},l=[{value:"About Citations in This Book",id:"about-citations-in-this-book",level:2},{value:"Citation Format",id:"citation-format",level:3},{value:"How to Use Citations",id:"how-to-use-citations",level:3},{value:"Module 1: ROS 2 Nervous System",id:"module-1-ros-2-nervous-system",level:2},{value:"ROS 2 Core Documentation",id:"ros-2-core-documentation",level:3},{value:"ROS 2 Tutorials and Guides",id:"ros-2-tutorials-and-guides",level:3},{value:"ROS Enhancement Proposals (REPs)",id:"ros-enhancement-proposals-reps",level:3},{value:"Module 2: Digital Twin - Simulation Environments",id:"module-2-digital-twin---simulation-environments",level:2},{value:"Gazebo Documentation",id:"gazebo-documentation",level:3},{value:"Isaac Sim Documentation",id:"isaac-sim-documentation",level:3},{value:"URDF and Robot Modeling",id:"urdf-and-robot-modeling",level:3},{value:"Module 3: AI Robot Brain - Perception and Intelligence",id:"module-3-ai-robot-brain---perception-and-intelligence",level:2},{value:"Computer Vision and Object Detection",id:"computer-vision-and-object-detection",level:3},{value:"SLAM and Navigation",id:"slam-and-navigation",level:3},{value:"Intel RealSense",id:"intel-realsense",level:3},{value:"Module 4: Vision-Language-Action Models",id:"module-4-vision-language-action-models",level:2},{value:"Large Language Models",id:"large-language-models",level:3},{value:"Voice Recognition",id:"voice-recognition",level:3},{value:"Vision-Language Models",id:"vision-language-models",level:3},{value:"Module 5: Capstone - Autonomous Humanoid System",id:"module-5-capstone---autonomous-humanoid-system",level:2},{value:"Robotics System Integration",id:"robotics-system-integration",level:3},{value:"Manipulation and Grasping",id:"manipulation-and-grasping",level:3},{value:"Dynamixel Servos",id:"dynamixel-servos",level:3},{value:"General References",id:"general-references",level:2},{value:"Embedded Computing",id:"embedded-computing",level:3},{value:"Docker and Containerization",id:"docker-and-containerization",level:3},{value:"Python and ML Frameworks",id:"python-and-ml-frameworks",level:3},{value:"Software Engineering",id:"software-engineering",level:3},{value:"Research Papers",id:"research-papers",level:2},{value:"Foundational Robotics",id:"foundational-robotics",level:3},{value:"Modern AI for Robotics",id:"modern-ai-for-robotics",level:3},{value:"How to Add Citations",id:"how-to-add-citations",level:2},{value:"Citation Statistics",id:"citation-statistics",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"citations-and-references",children:"Citations and References"})}),"\n",(0,o.jsx)(n.p,{children:"This page contains all citations referenced throughout the AI Humanoid Robotics Book, organized by module and formatted in APA 7th edition style."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Note"}),": This file is auto-generated from Context7 metadata using the citation conversion script at ",(0,o.jsx)(n.code,{children:"scripts/citations/context7_to_apa.py"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Last Updated"}),": 2025-12-07"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"about-citations-in-this-book",children:"About Citations in This Book"}),"\n",(0,o.jsxs)(n.p,{children:["This book uses a ",(0,o.jsx)(n.strong,{children:"research-concurrent methodology"}),", where citations are continuously updated as new documentation and research papers are published. Each citation is:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Linked to Context7 metadata"})," for version tracking and deeper exploration"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Formatted in APA 7th edition"})," for academic rigor"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Categorized by module"})," for easy navigation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Verified for accessibility"})," (all URLs checked during CI/CD)"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"citation-format",children:"Citation Format"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"In-Text Citation"}),":"]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsxs)(n.p,{children:["ROS 2 uses DDS for communication ",(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-001]"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Full Citation"})," (below):"]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Design"}),". ",(0,o.jsx)(n.a,{href:"https://design.ros2.org/",children:"https://design.ros2.org/"})]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"how-to-use-citations",children:"How to Use Citations"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Find Context"}),": Use Ctrl+F to search for citation IDs (e.g., ",(0,o.jsx)(n.code,{children:"CTX7-ROS2-001"}),")"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Explore Further"}),": Click URLs to access primary sources"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Verify Information"}),": All citations link to official documentation or peer-reviewed papers"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Suggest Additions"}),": Submit citation requests via ",(0,o.jsx)(n.a,{href:"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/issues",children:"GitHub Issues"})]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-1-ros-2-nervous-system",children:"Module 1: ROS 2 Nervous System"}),"\n",(0,o.jsx)(n.h3,{id:"ros-2-core-documentation",children:"ROS 2 Core Documentation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Documentation: Humble"}),". ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/",children:"https://docs.ros.org/en/humble/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-002]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Design"}),". ",(0,o.jsx)(n.a,{href:"https://design.ros2.org/",children:"https://design.ros2.org/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-003]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Concepts"}),". ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Concepts.html",children:"https://docs.ros.org/en/humble/Concepts.html"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-DDS-001]"})," Object Management Group. (2023). ",(0,o.jsx)(n.em,{children:"Data Distribution Service (DDS) Specification v1.4"}),". ",(0,o.jsx)(n.a,{href:"https://www.omg.org/spec/DDS/1.4",children:"https://www.omg.org/spec/DDS/1.4"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-QOS-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"About Quality of Service Settings"}),". ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Concepts/About-Quality-of-Service-Settings.html",children:"https://docs.ros.org/en/humble/Concepts/About-Quality-of-Service-Settings.html"})]}),"\n",(0,o.jsx)(n.h3,{id:"ros-2-tutorials-and-guides",children:"ROS 2 Tutorials and Guides"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-TUTORIAL-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Tutorials - Beginner: CLI Tools"}),". ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools.html",children:"https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools.html"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-TUTORIAL-002]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Tutorials - Writing a Simple Publisher and Subscriber (Python)"}),". ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html",children:"https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-COLCON-001]"})," colcon documentation. (2023). ",(0,o.jsx)(n.em,{children:"colcon - collective construction"}),". ",(0,o.jsx)(n.a,{href:"https://colcon.readthedocs.io/",children:"https://colcon.readthedocs.io/"})]}),"\n",(0,o.jsx)(n.h3,{id:"ros-enhancement-proposals-reps",children:"ROS Enhancement Proposals (REPs)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-REP-103]"})," Purvis, M., & Foote, T. (2010, updated 2020). ",(0,o.jsx)(n.em,{children:"REP 103 - Standard Units of Measure and Coordinate Conventions"}),". ",(0,o.jsx)(n.a,{href:"https://www.ros.org/reps/rep-0103.html",children:"https://www.ros.org/reps/rep-0103.html"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-REP-105]"})," Foote, T. (2010, updated 2020). ",(0,o.jsx)(n.em,{children:"REP 105 - Coordinate Frames for Mobile Platforms"}),". ",(0,o.jsx)(n.a,{href:"https://www.ros.org/reps/rep-0105.html",children:"https://www.ros.org/reps/rep-0105.html"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-2-digital-twin---simulation-environments",children:"Module 2: Digital Twin - Simulation Environments"}),"\n",(0,o.jsx)(n.h3,{id:"gazebo-documentation",children:"Gazebo Documentation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-GAZEBO-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"Gazebo Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://gazebosim.org/docs",children:"https://gazebosim.org/docs"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-GAZEBO-002]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"Gazebo Fortress Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://gazebosim.org/docs/fortress",children:"https://gazebosim.org/docs/fortress"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-GAZEBO-003]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Integration with Gazebo"}),". ",(0,o.jsx)(n.a,{href:"https://gazebosim.org/docs/fortress/ros2_integration",children:"https://gazebosim.org/docs/fortress/ros2_integration"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-SDF-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"SDF (Simulation Description Format) Specification"}),". ",(0,o.jsx)(n.a,{href:"http://sdformat.org/spec",children:"http://sdformat.org/spec"})]}),"\n",(0,o.jsx)(n.h3,{id:"isaac-sim-documentation",children:"Isaac Sim Documentation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ISAAC-001]"})," NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"Isaac Sim Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"https://docs.omniverse.nvidia.com/isaacsim/latest/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ISAAC-002]"})," NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"Isaac Sim ROS 2 Bridge"}),". ",(0,o.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/ros2_tutorials/index.html",children:"https://docs.omniverse.nvidia.com/isaacsim/latest/ros2_tutorials/index.html"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ISAAC-003]"})," NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"Isaac Sim Installation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/installation/install_workstation.html",children:"https://docs.omniverse.nvidia.com/isaacsim/latest/installation/install_workstation.html"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-USD-001]"})," Pixar Animation Studios. (2023). ",(0,o.jsx)(n.em,{children:"Universal Scene Description (USD)"}),". ",(0,o.jsx)(n.a,{href:"https://openusd.org/",children:"https://openusd.org/"})]}),"\n",(0,o.jsx)(n.h3,{id:"urdf-and-robot-modeling",children:"URDF and Robot Modeling"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-URDF-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"URDF - Unified Robot Description Format"}),". ",(0,o.jsx)(n.a,{href:"http://wiki.ros.org/urdf",children:"http://wiki.ros.org/urdf"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-URDF-002]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"URDF Tutorials"}),". ",(0,o.jsx)(n.a,{href:"http://wiki.ros.org/urdf/Tutorials",children:"http://wiki.ros.org/urdf/Tutorials"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-XACRO-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"Xacro - XML Macros for URDF"}),". ",(0,o.jsx)(n.a,{href:"http://wiki.ros.org/xacro",children:"http://wiki.ros.org/xacro"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-3-ai-robot-brain---perception-and-intelligence",children:"Module 3: AI Robot Brain - Perception and Intelligence"}),"\n",(0,o.jsx)(n.h3,{id:"computer-vision-and-object-detection",children:"Computer Vision and Object Detection"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-OPENCV-001]"})," OpenCV Team. (2023). ",(0,o.jsx)(n.em,{children:"OpenCV Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.opencv.org/4.x/",children:"https://docs.opencv.org/4.x/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-YOLO-001]"})," Ultralytics. (2023). ",(0,o.jsx)(n.em,{children:"YOLOv8 Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.ultralytics.com/",children:"https://docs.ultralytics.com/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-COCO-001]"})," Lin, T., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\xe1r, P., & Zitnick, C. L. (2014). Microsoft COCO: Common Objects in Context. In ",(0,o.jsx)(n.em,{children:"Computer Vision \u2013 ECCV 2014"})," (pp. 740-755). Springer. ",(0,o.jsx)(n.a,{href:"https://cocodataset.org/",children:"https://cocodataset.org/"})]}),"\n",(0,o.jsx)(n.h3,{id:"slam-and-navigation",children:"SLAM and Navigation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-NAV2-001]"})," Open Navigation. (2023). ",(0,o.jsx)(n.em,{children:"Navigation2 Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://navigation.ros.org/",children:"https://navigation.ros.org/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-SLAM-001]"})," Open Robotics. (2023). ",(0,o.jsx)(n.em,{children:"SLAM Toolbox Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://github.com/SteveMacenski/slam_toolbox",children:"https://github.com/SteveMacenski/slam_toolbox"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-VSLAM-001]"})," Mur-Artal, R., Montiel, J. M. M., & Tard\xf3s, J. D. (2015). ORB-SLAM: A versatile and accurate monocular SLAM system. ",(0,o.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 31(5), 1147-1163. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1109/TRO.2015.2463671",children:"https://doi.org/10.1109/TRO.2015.2463671"})]}),"\n",(0,o.jsx)(n.h3,{id:"intel-realsense",children:"Intel RealSense"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-REALSENSE-001]"})," Intel Corporation. (2023). ",(0,o.jsx)(n.em,{children:"Intel RealSense D435i Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://www.intelrealsense.com/depth-camera-d435i/",children:"https://www.intelrealsense.com/depth-camera-d435i/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-REALSENSE-002]"})," Intel Corporation. (2023). ",(0,o.jsx)(n.em,{children:"librealsense SDK"}),". ",(0,o.jsx)(n.a,{href:"https://github.com/IntelRealSense/librealsense",children:"https://github.com/IntelRealSense/librealsense"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-REALSENSE-ROS-001]"})," Intel Corporation. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Wrapper for Intel RealSense"}),". ",(0,o.jsx)(n.a,{href:"https://github.com/IntelRealSense/realsense-ros",children:"https://github.com/IntelRealSense/realsense-ros"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-4-vision-language-action-models",children:"Module 4: Vision-Language-Action Models"}),"\n",(0,o.jsx)(n.h3,{id:"large-language-models",children:"Large Language Models"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-CLAUDE-001]"})," Anthropic. (2024). ",(0,o.jsx)(n.em,{children:"Claude API Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.anthropic.com/",children:"https://docs.anthropic.com/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-CLAUDE-002]"})," Anthropic. (2024). ",(0,o.jsx)(n.em,{children:"Introducing Claude Sonnet 4.5"}),". ",(0,o.jsx)(n.a,{href:"https://www.anthropic.com/news/claude-sonnet-4-5",children:"https://www.anthropic.com/news/claude-sonnet-4-5"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-LLM-ROBOTICS-001]"})," Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., ... & Zeng, A. (2022). Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. In ",(0,o.jsx)(n.em,{children:"Conference on Robot Learning (CoRL)"}),". ",(0,o.jsx)(n.a,{href:"https://say-can.github.io/",children:"https://say-can.github.io/"})]}),"\n",(0,o.jsx)(n.h3,{id:"voice-recognition",children:"Voice Recognition"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-WHISPER-001]"})," Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2022). Robust Speech Recognition via Large-Scale Weak Supervision. ",(0,o.jsx)(n.em,{children:"arXiv preprint arXiv:2212.04356"}),". ",(0,o.jsx)(n.a,{href:"https://arxiv.org/abs/2212.04356",children:"https://arxiv.org/abs/2212.04356"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-WHISPER-002]"})," OpenAI. (2023). ",(0,o.jsx)(n.em,{children:"Whisper Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://github.com/openai/whisper",children:"https://github.com/openai/whisper"})]}),"\n",(0,o.jsx)(n.h3,{id:"vision-language-models",children:"Vision-Language Models"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-VLA-001]"})," Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabis, J., Finn, C., ... & Zitkovich, B. (2023). RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control. In ",(0,o.jsx)(n.em,{children:"Conference on Robot Learning (CoRL)"}),". ",(0,o.jsx)(n.a,{href:"https://robotics-transformer2.github.io/",children:"https://robotics-transformer2.github.io/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-VLA-002]"})," Driess, D., Xia, F., Sajjadi, M. S., Lynch, C., Chowdhery, A., Ichter, B., ... & Florence, P. (2023). PaLM-E: An Embodied Multimodal Language Model. In ",(0,o.jsx)(n.em,{children:"International Conference on Machine Learning (ICML)"}),". ",(0,o.jsx)(n.a,{href:"https://palm-e.github.io/",children:"https://palm-e.github.io/"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-5-capstone---autonomous-humanoid-system",children:"Module 5: Capstone - Autonomous Humanoid System"}),"\n",(0,o.jsx)(n.h3,{id:"robotics-system-integration",children:"Robotics System Integration"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-ROS2-INTEGRATION-001]"})," Macenski, S., Foote, T., Gerkey, B., Lalancette, C., & Woodall, W. (2022). Robot Operating System 2: Design, architecture, and uses in the wild. ",(0,o.jsx)(n.em,{children:"Science Robotics"}),", 7(66), eabm6074. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1126/scirobotics.abm6074",children:"https://doi.org/10.1126/scirobotics.abm6074"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-BEHAVIOR-TREES-001]"})," Colledanchise, M., & \xd6gren, P. (2018). ",(0,o.jsx)(n.em,{children:"Behavior Trees in Robotics and AI: An Introduction"}),". CRC Press. ",(0,o.jsx)(n.a,{href:"https://arxiv.org/abs/1709.00084",children:"https://arxiv.org/abs/1709.00084"})]}),"\n",(0,o.jsx)(n.h3,{id:"manipulation-and-grasping",children:"Manipulation and Grasping"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-GRASP-001]"})," Bohg, J., Morales, A., Asfour, T., & Kragic, D. (2014). Data-driven grasp synthesis\u2014A survey. ",(0,o.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 30(2), 289-309. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1109/TRO.2013.2289018",children:"https://doi.org/10.1109/TRO.2013.2289018"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-MOVEIT-001]"})," MoveIt Maintainers. (2023). ",(0,o.jsx)(n.em,{children:"MoveIt 2 Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://moveit.picknik.ai/",children:"https://moveit.picknik.ai/"})]}),"\n",(0,o.jsx)(n.h3,{id:"dynamixel-servos",children:"Dynamixel Servos"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-DYNAMIXEL-001]"})," ROBOTIS. (2023). ",(0,o.jsx)(n.em,{children:"Dynamixel XM430 e-Manual"}),". ",(0,o.jsx)(n.a,{href:"https://emanual.robotis.com/docs/en/dxl/x/xm430-w350/",children:"https://emanual.robotis.com/docs/en/dxl/x/xm430-w350/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-DYNAMIXEL-SDK-001]"})," ROBOTIS. (2023). ",(0,o.jsx)(n.em,{children:"Dynamixel SDK Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://emanual.robotis.com/docs/en/software/dynamixel/dynamixel_sdk/overview/",children:"https://emanual.robotis.com/docs/en/software/dynamixel/dynamixel_sdk/overview/"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"general-references",children:"General References"}),"\n",(0,o.jsx)(n.h3,{id:"embedded-computing",children:"Embedded Computing"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-JETSON-001]"})," NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"Jetson Orin Nano Developer Kit"}),". ",(0,o.jsx)(n.a,{href:"https://developer.nvidia.com/embedded/jetson-orin-nano-developer-kit",children:"https://developer.nvidia.com/embedded/jetson-orin-nano-developer-kit"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-JETSON-002]"})," NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"JetPack SDK Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://developer.nvidia.com/embedded/jetpack",children:"https://developer.nvidia.com/embedded/jetpack"})]}),"\n",(0,o.jsx)(n.h3,{id:"docker-and-containerization",children:"Docker and Containerization"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-DOCKER-001]"})," Docker, Inc. (2023). ",(0,o.jsx)(n.em,{children:"Docker Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.docker.com/",children:"https://docs.docker.com/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-NVIDIA-DOCKER-001]"})," NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"NVIDIA Container Toolkit"}),". ",(0,o.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/",children:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/"})]}),"\n",(0,o.jsx)(n.h3,{id:"python-and-ml-frameworks",children:"Python and ML Frameworks"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-PYTORCH-001]"})," Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. In ",(0,o.jsx)(n.em,{children:"Advances in Neural Information Processing Systems"})," (pp. 8024-8035). ",(0,o.jsx)(n.a,{href:"https://pytorch.org/",children:"https://pytorch.org/"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-NUMPY-001]"})," Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., ... & Oliphant, T. E. (2020). Array programming with NumPy. ",(0,o.jsx)(n.em,{children:"Nature"}),", 585(7825), 357-362. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1038/s41586-020-2649-2",children:"https://doi.org/10.1038/s41586-020-2649-2"})]}),"\n",(0,o.jsx)(n.h3,{id:"software-engineering",children:"Software Engineering"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-GIT-001]"})," Chacon, S., & Straub, B. (2014). ",(0,o.jsx)(n.em,{children:"Pro Git"})," (2nd ed.). Apress. ",(0,o.jsx)(n.a,{href:"https://git-scm.com/book/en/v2",children:"https://git-scm.com/book/en/v2"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-GITHUB-ACTIONS-001]"})," GitHub, Inc. (2023). ",(0,o.jsx)(n.em,{children:"GitHub Actions Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.github.com/en/actions",children:"https://docs.github.com/en/actions"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[CTX7-PYTEST-001]"})," pytest developers. (2023). ",(0,o.jsx)(n.em,{children:"pytest Documentation"}),". ",(0,o.jsx)(n.a,{href:"https://docs.pytest.org/",children:"https://docs.pytest.org/"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"research-papers",children:"Research Papers"}),"\n",(0,o.jsx)(n.h3,{id:"foundational-robotics",children:"Foundational Robotics"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[RP-001]"})," Brooks, R. A. (1986). A robust layered control system for a mobile robot. ",(0,o.jsx)(n.em,{children:"IEEE Journal on Robotics and Automation"}),", 2(1), 14-23. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1109/JRA.1986.1087032",children:"https://doi.org/10.1109/JRA.1986.1087032"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[RP-002]"})," Khatib, O. (1986). Real-time obstacle avoidance for manipulators and mobile robots. ",(0,o.jsx)(n.em,{children:"The International Journal of Robotics Research"}),", 5(1), 90-98. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1177/027836498600500106",children:"https://doi.org/10.1177/027836498600500106"})]}),"\n",(0,o.jsx)(n.h3,{id:"modern-ai-for-robotics",children:"Modern AI for Robotics"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[RP-003]"})," Levine, S., Pastor, P., Krizhevsky, A., Ibarz, J., & Quillen, D. (2018). Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. ",(0,o.jsx)(n.em,{children:"The International Journal of Robotics Research"}),", 37(4-5), 421-436. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1177/0278364917710318",children:"https://doi.org/10.1177/0278364917710318"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"[RP-004]"})," Ichter, B., Pavone, M., & Schaal, S. (2018). Robot motion planning in learned latent spaces. ",(0,o.jsx)(n.em,{children:"IEEE Robotics and Automation Letters"}),", 4(3), 2407-2414. ",(0,o.jsx)(n.a,{href:"https://doi.org/10.1109/LRA.2019.2901394",children:"https://doi.org/10.1109/LRA.2019.2901394"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"how-to-add-citations",children:"How to Add Citations"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"For Contributors"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Add citation metadata to ",(0,o.jsx)(n.code,{children:".context7/metadata/citations.json"})]}),"\n",(0,o.jsxs)(n.li,{children:["Run citation generation script:","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"python3 scripts/citations/context7_to_apa.py\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Verify output in ",(0,o.jsx)(n.code,{children:"docs/appendices/citations.md"})]}),"\n",(0,o.jsx)(n.li,{children:"Submit pull request with both files"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Citation Metadata Format"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "id": "CTX7-EXAMPLE-001",\n  "type": "documentation",\n  "authors": ["Author Name"],\n  "year": 2023,\n  "title": "Document Title",\n  "url": "https://example.com",\n  "doi": null,\n  "module": "module-01"\n}\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"citation-statistics",children:"Citation Statistics"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Total Citations"}),": TBD (to be populated from Context7)"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"By Module"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Module 1 (ROS 2): Target 15 citations"}),"\n",(0,o.jsx)(n.li,{children:"Module 2 (Digital Twin): Target 20 citations"}),"\n",(0,o.jsx)(n.li,{children:"Module 3 (AI Brain): Target 25 citations"}),"\n",(0,o.jsx)(n.li,{children:"Module 4 (VLA): Target 30 citations"}),"\n",(0,o.jsx)(n.li,{children:"Module 5 (Capstone): Target 60 citations"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"By Type"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Official Documentation: ~60%"}),"\n",(0,o.jsx)(n.li,{children:"Research Papers: ~25%"}),"\n",(0,o.jsx)(n.li,{children:"Vendor Guides: ~15%"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Found a broken link or missing citation?"})," Report it via ",(0,o.jsx)(n.a,{href:"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/issues",children:"GitHub Issues"})," with the citation ID."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Last Auto-Generated"}),": Run ",(0,o.jsx)(n.code,{children:"python3 scripts/citations/context7_to_apa.py"})," to update"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var s=i(6540);const o={},t=s.createContext(o);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);