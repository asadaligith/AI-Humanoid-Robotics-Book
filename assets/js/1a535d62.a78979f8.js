"use strict";(self.webpackChunkai_humanoid_robotics_book=self.webpackChunkai_humanoid_robotics_book||[]).push([[3258],{889:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"rag-chatbot/architecture","title":"RAG Chatbot Architecture","description":"Overview","source":"@site/docs/rag-chatbot/architecture.md","sourceDirName":"rag-chatbot","slug":"/rag-chatbot/architecture","permalink":"/AI-Humanoid-Robotics-Book/docs/rag-chatbot/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/asadaligith/AI-Humanoid-Robotics-Book/tree/main/docs/rag-chatbot/architecture.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chatbot User Guide","permalink":"/AI-Humanoid-Robotics-Book/docs/rag-chatbot/user-guide"},"next":{"title":"RAG Chatbot Setup Guide","permalink":"/AI-Humanoid-Robotics-Book/docs/rag-chatbot/setup"}}');var r=t(4848),i=t(8453);const o={},a="RAG Chatbot Architecture",c={},l=[{value:"Overview",id:"overview",level:2},{value:"\u2728 New Features",id:"-new-features",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Component Details",id:"component-details",level:2},{value:"1. Document Ingestion Pipeline",id:"1-document-ingestion-pipeline",level:3},{value:"2. Query Processing",id:"2-query-processing",level:3},{value:"3. Response Generation",id:"3-response-generation",level:3},{value:"4. FastAPI Application",id:"4-fastapi-application",level:3},{value:"Database Schema (PostgreSQL)",id:"database-schema-postgresql",level:2},{value:"Qdrant Collection Schema",id:"qdrant-collection-schema",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"1. Caching Strategy",id:"1-caching-strategy",level:3},{value:"2. Rate Limiting",id:"2-rate-limiting",level:3},{value:"3. Cost Optimization",id:"3-cost-optimization",level:3},{value:"4. Scalability",id:"4-scalability",level:3},{value:"Security",id:"security",level:2},{value:"Monitoring &amp; Analytics",id:"monitoring--analytics",level:2},{value:"Deployment",id:"deployment",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"rag-chatbot-architecture",children:"RAG Chatbot Architecture"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"The Retrieval-Augmented Generation (RAG) chatbot provides intelligent, context-aware assistance for the AI & Humanoid Robotics course. It combines vector search, PostgreSQL metadata storage, and Claude's language understanding to answer student questions."}),"\n",(0,r.jsx)(n.h2,{id:"-new-features",children:"\u2728 New Features"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Enhanced Conversational AI"})," (Latest Update):"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Greeting Support"}),': Responds naturally to casual greetings ("hi", "hello", "hey", etc.)']}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Improved Answer Quality"}),": Resolved response generation issues - now provides accurate, comprehensive answers"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Full Book Integration"}),": All 32 chapters from 5 modules ingested into RAG system"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Context-Aware Responses"}),": Understands course structure and provides relevant module references"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Interactive Learning"}),": Asks clarifying questions when user intent is ambiguous"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     User Interface                           \u2502\n\u2502              (Web Chat Widget + CLI)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   API Gateway (FastAPI)                      \u2502\n\u2502  - Request validation                                        \u2502\n\u2502  - Rate limiting                                             \u2502\n\u2502  - Authentication                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2193                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Query Processor  \u2502       \u2502 Session Manager  \u2502\n\u2502  - Intent detect  \u2502       \u2502 - User history   \u2502\n\u2502  - Query rewrite  \u2502       \u2502 - Context cache  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Embedding & Retrieval Pipeline                  \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Embeddings  \u2502\u2500\u2500\u2500\u2192\u2502   Qdrant     \u2502\u2500\u2500\u2500\u2192\u2502  Reranking   \u2502  \u2502\n\u2502  \u2502  (OpenAI)    \u2502    \u2502 Vector Store \u2502    \u2502  (Optional)  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                PostgreSQL (Neon)                             \u2502\n\u2502  - Document metadata                                         \u2502\n\u2502  - User sessions                                             \u2502\n\u2502  - Feedback tracking                                         \u2502\n\u2502  - Analytics                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Claude API (Response Generation)                \u2502\n\u2502  - Context: Retrieved docs                                   \u2502\n\u2502  - System: Course assistant persona                          \u2502\n\u2502  - Tools: Code execution, navigation                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Response                                 \u2502\n\u2502  - Formatted answer                                          \u2502\n\u2502  - Source citations                                          \u2502\n\u2502  - Suggested next steps                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h2,{id:"component-details",children:"Component Details"}),"\n",(0,r.jsx)(n.h3,{id:"1-document-ingestion-pipeline",children:"1. Document Ingestion Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'"""\nIngests course content into vector database\n"""\n\nclass DocumentIngestionPipeline:\n    def __init__(self, qdrant_client, postgres_conn, openai_api_key):\n        self.qdrant = qdrant_client\n        self.db = postgres_conn\n        self.embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n\n    def ingest_directory(self, docs_path: str):\n        """Ingest all markdown files from documentation."""\n        documents = []\n\n        for md_file in Path(docs_path).rglob("*.md"):\n            # Parse markdown\n            content = md_file.read_text()\n            metadata = self.extract_metadata(md_file, content)\n\n            # Chunk document\n            chunks = self.chunk_document(content, metadata)\n            documents.extend(chunks)\n\n        # Generate embeddings\n        embeddings = self.embeddings.embed_documents([d[\'text\'] for d in documents])\n\n        # Store in Qdrant\n        self.qdrant.upsert(\n            collection_name="course_docs",\n            points=[\n                {\n                    "id": i,\n                    "vector": emb,\n                    "payload": doc\n                }\n                for i, (emb, doc) in enumerate(zip(embeddings, documents))\n            ]\n        )\n\n        # Store metadata in PostgreSQL\n        self.db.execute_many(\n            "INSERT INTO documents (id, title, url, module, chapter) VALUES (%s, %s, %s, %s, %s)",\n            [(d[\'id\'], d[\'title\'], d[\'url\'], d[\'module\'], d[\'chapter\']) for d in documents]\n        )\n\n    def chunk_document(self, content: str, metadata: dict, chunk_size=512, overlap=50):\n        """Split document into overlapping chunks."""\n        chunks = []\n        sentences = content.split(\'\\n\\n\')  # Split by paragraphs\n\n        current_chunk = []\n        current_size = 0\n\n        for sentence in sentences:\n            tokens = len(sentence.split())\n\n            if current_size + tokens > chunk_size and current_chunk:\n                # Save chunk\n                chunks.append({\n                    \'text\': \'\\n\\n\'.join(current_chunk),\n                    **metadata,\n                    \'chunk_index\': len(chunks)\n                })\n\n                # Keep overlap\n                overlap_size = 0\n                overlap_chunk = []\n                for s in reversed(current_chunk):\n                    overlap_size += len(s.split())\n                    overlap_chunk.insert(0, s)\n                    if overlap_size >= overlap:\n                        break\n\n                current_chunk = overlap_chunk\n                current_size = overlap_size\n\n            current_chunk.append(sentence)\n            current_size += tokens\n\n        # Add final chunk\n        if current_chunk:\n            chunks.append({\n                \'text\': \'\\n\\n\'.join(current_chunk),\n                **metadata,\n                \'chunk_index\': len(chunks)\n            })\n\n        return chunks\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-query-processing",children:"2. Query Processing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'"""\nProcesses user queries and retrieves relevant context\n"""\n\nclass QueryProcessor:\n    def __init__(self, qdrant_client, embeddings):\n        self.qdrant = qdrant_client\n        self.embeddings = embeddings\n\n    def process_query(self, query: str, filters: dict = None, top_k: int = 5):\n        """Process query and retrieve relevant documents."""\n\n        # Generate query embedding\n        query_embedding = self.embeddings.embed_query(query)\n\n        # Search Qdrant\n        search_results = self.qdrant.search(\n            collection_name="course_docs",\n            query_vector=query_embedding,\n            limit=top_k,\n            query_filter=self.build_filter(filters) if filters else None\n        )\n\n        # Extract contexts\n        contexts = []\n        for result in search_results:\n            contexts.append({\n                \'text\': result.payload[\'text\'],\n                \'score\': result.score,\n                \'metadata\': {\n                    \'title\': result.payload[\'title\'],\n                    \'url\': result.payload[\'url\'],\n                    \'module\': result.payload.get(\'module\'),\n                    \'chapter\': result.payload.get(\'chapter\'),\n                }\n            })\n\n        return contexts\n\n    def build_filter(self, filters: dict):\n        """Build Qdrant filter from dict."""\n        conditions = []\n\n        for key, value in filters.items():\n            conditions.append({\n                "key": key,\n                "match": {"value": value}\n            })\n\n        return {"must": conditions} if conditions else None\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-response-generation",children:"3. Response Generation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'"""\nGenerates responses using Claude with retrieved context\n"""\n\nimport anthropic\n\nclass ResponseGenerator:\n    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-20241022"):\n        self.client = anthropic.Anthropic(api_key=api_key)\n        self.model = model\n\n    def generate_response(self, query: str, contexts: list, conversation_history: list = None):\n        """Generate response with retrieved context."""\n\n        # Build context string\n        context_str = self.format_contexts(contexts)\n\n        # System prompt\n        system_prompt = f"""You are an intelligent assistant for the AI & Humanoid Robotics course. Help students learn ROS 2, Gazebo, Isaac Sim, and autonomous robotics.\n\nRetrieved Context:\n{context_str}\n\nGuidelines:\n- Answer based on the retrieved context when possible\n- Cite sources using [Module X, Chapter Y] notation\n- Provide code examples when relevant\n- Suggest related topics for deeper learning\n- If the question is outside the course scope, politely redirect\n- Be encouraging and educational"""\n\n        # Build message history\n        messages = []\n        if conversation_history:\n            messages.extend(conversation_history)\n\n        messages.append({\n            "role": "user",\n            "content": query\n        })\n\n        # Generate response\n        response = self.client.messages.create(\n            model=self.model,\n            max_tokens=2048,\n            system=system_prompt,\n            messages=messages\n        )\n\n        answer = response.content[0].text\n\n        # Add source citations\n        sources = self.extract_sources(contexts)\n\n        return {\n            \'answer\': answer,\n            \'sources\': sources,\n            \'contexts_used\': len(contexts)\n        }\n\n    def format_contexts(self, contexts: list) -> str:\n        """Format retrieved contexts for prompt."""\n        formatted = []\n\n        for i, ctx in enumerate(contexts, 1):\n            meta = ctx[\'metadata\']\n            formatted.append(\n                f"[Source {i}] {meta.get(\'title\', \'Unknown\')}\\n"\n                f"Module: {meta.get(\'module\', \'N/A\')}, Chapter: {meta.get(\'chapter\', \'N/A\')}\\n"\n                f"Content: {ctx[\'text\']}\\n"\n            )\n\n        return "\\n".join(formatted)\n\n    def extract_sources(self, contexts: list) -> list:\n        """Extract source references."""\n        sources = []\n\n        for ctx in contexts:\n            meta = ctx[\'metadata\']\n            sources.append({\n                \'title\': meta.get(\'title\'),\n                \'url\': meta.get(\'url\'),\n                \'module\': meta.get(\'module\'),\n                \'chapter\': meta.get(\'chapter\'),\n                \'relevance_score\': ctx[\'score\']\n            })\n\n        return sources\n'})}),"\n",(0,r.jsx)(n.h3,{id:"4-fastapi-application",children:"4. FastAPI Application"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'"""\nAPI endpoints for chatbot\n"""\n\nfrom fastapi import FastAPI, HTTPException, Depends\nfrom pydantic import BaseModel\nfrom typing import List, Optional\nimport uvicorn\n\napp = FastAPI(title="RAG Chatbot API")\n\nclass ChatRequest(BaseModel):\n    query: str\n    session_id: Optional[str] = None\n    filters: Optional[dict] = None\n    top_k: int = 5\n\nclass ChatResponse(BaseModel):\n    answer: str\n    sources: List[dict]\n    session_id: str\n\nclass Chatbot:\n    def __init__(self):\n        self.query_processor = QueryProcessor(qdrant_client, embeddings)\n        self.response_generator = ResponseGenerator(claude_api_key)\n        self.session_manager = SessionManager(db_connection)\n\n    async def process_chat(self, request: ChatRequest) -> ChatResponse:\n        """Process chat request."""\n\n        # Get or create session\n        session = self.session_manager.get_or_create(request.session_id)\n\n        # Retrieve context\n        contexts = self.query_processor.process_query(\n            request.query,\n            filters=request.filters,\n            top_k=request.top_k\n        )\n\n        # Generate response\n        result = self.response_generator.generate_response(\n            request.query,\n            contexts,\n            conversation_history=session.history\n        )\n\n        # Update session\n        session.add_exchange(request.query, result[\'answer\'])\n\n        # Log to database\n        self.log_interaction(session.id, request.query, result)\n\n        return ChatResponse(\n            answer=result[\'answer\'],\n            sources=result[\'sources\'],\n            session_id=session.id\n        )\n\nchatbot = Chatbot()\n\n@app.post("/chat", response_model=ChatResponse)\nasync def chat(request: ChatRequest):\n    """Chat endpoint."""\n    try:\n        return await chatbot.process_chat(request)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get("/health")\nasync def health():\n    """Health check."""\n    return {"status": "healthy"}\n\nif __name__ == "__main__":\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"database-schema-postgresql",children:"Database Schema (PostgreSQL)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Documents metadata\nCREATE TABLE documents (\n    id SERIAL PRIMARY KEY,\n    title VARCHAR(255) NOT NULL,\n    url VARCHAR(512),\n    module VARCHAR(50),\n    chapter VARCHAR(50),\n    content_hash VARCHAR(64) UNIQUE,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Chat sessions\nCREATE TABLE chat_sessions (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id VARCHAR(100),\n    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    message_count INTEGER DEFAULT 0\n);\n\n-- Chat messages\nCREATE TABLE chat_messages (\n    id SERIAL PRIMARY KEY,\n    session_id UUID REFERENCES chat_sessions(id),\n    role VARCHAR(20) NOT NULL,  -- 'user' or 'assistant'\n    content TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Retrieved documents (for analytics)\nCREATE TABLE retrieved_documents (\n    id SERIAL PRIMARY KEY,\n    session_id UUID REFERENCES chat_sessions(id),\n    document_id INTEGER REFERENCES documents(id),\n    relevance_score FLOAT,\n    query TEXT,\n    retrieved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- User feedback\nCREATE TABLE feedback (\n    id SERIAL PRIMARY KEY,\n    session_id UUID REFERENCES chat_sessions(id),\n    message_id INTEGER,\n    rating INTEGER CHECK (rating BETWEEN 1 AND 5),\n    comment TEXT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Indexes\nCREATE INDEX idx_sessions_user ON chat_sessions(user_id);\nCREATE INDEX idx_messages_session ON chat_messages(session_id);\nCREATE INDEX idx_documents_module ON documents(module);\nCREATE INDEX idx_retrieved_query ON retrieved_documents(query);\n"})}),"\n",(0,r.jsx)(n.h2,{id:"qdrant-collection-schema",children:"Qdrant Collection Schema"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\n\n# Initialize client\nclient = QdrantClient(url="https://your-cluster.qdrant.io", api_key="your-key")\n\n# Create collection\nclient.create_collection(\n    collection_name="course_docs",\n    vectors_config=VectorParams(\n        size=1536,  # OpenAI text-embedding-3-small dimension\n        distance=Distance.COSINE\n    )\n)\n\n# Create payload indexes for filtering\nclient.create_payload_index(\n    collection_name="course_docs",\n    field_name="module",\n    field_schema="keyword"\n)\n\nclient.create_payload_index(\n    collection_name="course_docs",\n    field_name="chapter",\n    field_schema="keyword"\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,r.jsx)(n.h3,{id:"1-caching-strategy",children:"1. Caching Strategy"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cache embeddings for frequently asked questions"}),"\n",(0,r.jsx)(n.li,{children:"Cache Claude responses for identical queries"}),"\n",(0,r.jsx)(n.li,{children:"Use Redis for session management"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-rate-limiting",children:"2. Rate Limiting"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"10 requests/minute per user"}),"\n",(0,r.jsx)(n.li,{children:"1000 requests/day per API key"}),"\n",(0,r.jsx)(n.li,{children:"Exponential backoff on API failures"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-cost-optimization",children:"3. Cost Optimization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use text-embedding-3-small ($0.02/1M tokens) instead of ada-002"}),"\n",(0,r.jsx)(n.li,{children:"Cache common query embeddings"}),"\n",(0,r.jsx)(n.li,{children:"Batch document processing during ingestion"}),"\n",(0,r.jsx)(n.li,{children:"Use Claude 3.5 Sonnet (not Opus) for most queries"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-scalability",children:"4. Scalability"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Horizontal scaling with load balancer"}),"\n",(0,r.jsx)(n.li,{children:"Database connection pooling"}),"\n",(0,r.jsx)(n.li,{children:"Async I/O for API calls"}),"\n",(0,r.jsx)(n.li,{children:"Qdrant cluster for large document collections"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"security",children:"Security"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"API Key Management"}),": Store in environment variables, never in code"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input Validation"}),": Sanitize user queries, prevent prompt injection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Rate Limiting"}),": Prevent abuse and DoS attacks"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Authentication"}),": Optional user authentication for personalized experience"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Privacy"}),": Anonymize logs, respect user data preferences"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"monitoring--analytics",children:"Monitoring & Analytics"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Track key metrics\nclass Analytics:\n    def track_query(self, session_id, query, response_time, contexts_count):\n        """Track query metrics."""\n        self.db.execute(\n            """\n            INSERT INTO query_analytics\n            (session_id, query, response_time_ms, contexts_retrieved, timestamp)\n            VALUES (%s, %s, %s, %s, NOW())\n            """,\n            (session_id, query, response_time * 1000, contexts_count)\n        )\n\n    def get_metrics(self, days=7):\n        """Get analytics for last N days."""\n        return self.db.query(\n            """\n            SELECT\n                DATE(timestamp) as date,\n                COUNT(*) as total_queries,\n                AVG(response_time_ms) as avg_response_time,\n                AVG(contexts_retrieved) as avg_contexts\n            FROM query_analytics\n            WHERE timestamp >= NOW() - INTERVAL \'%s days\'\n            GROUP BY DATE(timestamp)\n            ORDER BY date DESC\n            """,\n            (days,)\n        )\n'})}),"\n",(0,r.jsx)(n.h2,{id:"deployment",children:"Deployment"}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.a,{href:"/AI-Humanoid-Robotics-Book/docs/rag-chatbot/deployment",children:"deployment.md"})," for production deployment instructions."]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Setup"}),": Follow ",(0,r.jsx)(n.a,{href:"/AI-Humanoid-Robotics-Book/docs/rag-chatbot/setup",children:"setup.md"})," for local development"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integration"}),": See ",(0,r.jsx)(n.a,{href:"integration.md",children:"integration.md"})," for embedding in Docusaurus"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Customization"}),": Review ",(0,r.jsx)(n.a,{href:"customization.md",children:"customization.md"})," for branding"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://qdrant.tech/documentation/",children:"Qdrant Documentation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://neon.tech/docs",children:"Neon PostgreSQL"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.anthropic.com/",children:"Anthropic Claude API"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://fastapi.tiangolo.com/",children:"FastAPI Documentation"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var s=t(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);