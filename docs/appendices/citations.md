---
sidebar_position: 4
---

# Citations and References

This page contains all citations referenced throughout the AI Humanoid Robotics Book, organized by module and formatted in APA 7th edition style.

**Note**: This file is auto-generated from Context7 metadata using the citation conversion script at `scripts/citations/context7_to_apa.py`.

**Last Updated**: 2025-12-07

---

## About Citations in This Book

This book uses a **research-concurrent methodology**, where citations are continuously updated as new documentation and research papers are published. Each citation is:

- **Linked to Context7 metadata** for version tracking and deeper exploration
- **Formatted in APA 7th edition** for academic rigor
- **Categorized by module** for easy navigation
- **Verified for accessibility** (all URLs checked during CI/CD)

### Citation Format

**In-Text Citation**:
> ROS 2 uses DDS for communication **[CTX7-ROS2-001]**.

**Full Citation** (below):
> **[CTX7-ROS2-001]** Open Robotics. (2023). *ROS 2 Design*. https://design.ros2.org/

### How to Use Citations

- **Find Context**: Use Ctrl+F to search for citation IDs (e.g., `CTX7-ROS2-001`)
- **Explore Further**: Click URLs to access primary sources
- **Verify Information**: All citations link to official documentation or peer-reviewed papers
- **Suggest Additions**: Submit citation requests via [GitHub Issues](https://github.com/asadaligith/AI-Humanoid-Robotics-Book/issues)

---

## Module 1: ROS 2 Nervous System

### ROS 2 Core Documentation

**[CTX7-ROS2-001]** Open Robotics. (2023). *ROS 2 Documentation: Humble*. https://docs.ros.org/en/humble/

**[CTX7-ROS2-002]** Open Robotics. (2023). *ROS 2 Design*. https://design.ros2.org/

**[CTX7-ROS2-003]** Open Robotics. (2023). *ROS 2 Concepts*. https://docs.ros.org/en/humble/Concepts.html

**[CTX7-DDS-001]** Object Management Group. (2023). *Data Distribution Service (DDS) Specification v1.4*. https://www.omg.org/spec/DDS/1.4

**[CTX7-QOS-001]** Open Robotics. (2023). *About Quality of Service Settings*. https://docs.ros.org/en/humble/Concepts/About-Quality-of-Service-Settings.html

### ROS 2 Tutorials and Guides

**[CTX7-ROS2-TUTORIAL-001]** Open Robotics. (2023). *ROS 2 Tutorials - Beginner: CLI Tools*. https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools.html

**[CTX7-ROS2-TUTORIAL-002]** Open Robotics. (2023). *ROS 2 Tutorials - Writing a Simple Publisher and Subscriber (Python)*. https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html

**[CTX7-COLCON-001]** colcon documentation. (2023). *colcon - collective construction*. https://colcon.readthedocs.io/

### ROS Enhancement Proposals (REPs)

**[CTX7-REP-103]** Purvis, M., & Foote, T. (2010, updated 2020). *REP 103 - Standard Units of Measure and Coordinate Conventions*. https://www.ros.org/reps/rep-0103.html

**[CTX7-REP-105]** Foote, T. (2010, updated 2020). *REP 105 - Coordinate Frames for Mobile Platforms*. https://www.ros.org/reps/rep-0105.html

---

## Module 2: Digital Twin - Simulation Environments

### Gazebo Documentation

**[CTX7-GAZEBO-001]** Open Robotics. (2023). *Gazebo Documentation*. https://gazebosim.org/docs

**[CTX7-GAZEBO-002]** Open Robotics. (2023). *Gazebo Fortress Documentation*. https://gazebosim.org/docs/fortress

**[CTX7-GAZEBO-003]** Open Robotics. (2023). *ROS 2 Integration with Gazebo*. https://gazebosim.org/docs/fortress/ros2_integration

**[CTX7-SDF-001]** Open Robotics. (2023). *SDF (Simulation Description Format) Specification*. http://sdformat.org/spec

### Isaac Sim Documentation

**[CTX7-ISAAC-001]** NVIDIA. (2023). *Isaac Sim Documentation*. https://docs.omniverse.nvidia.com/isaacsim/latest/

**[CTX7-ISAAC-002]** NVIDIA. (2023). *Isaac Sim ROS 2 Bridge*. https://docs.omniverse.nvidia.com/isaacsim/latest/ros2_tutorials/index.html

**[CTX7-ISAAC-003]** NVIDIA. (2023). *Isaac Sim Installation*. https://docs.omniverse.nvidia.com/isaacsim/latest/installation/install_workstation.html

**[CTX7-USD-001]** Pixar Animation Studios. (2023). *Universal Scene Description (USD)*. https://openusd.org/

### URDF and Robot Modeling

**[CTX7-URDF-001]** Open Robotics. (2023). *URDF - Unified Robot Description Format*. http://wiki.ros.org/urdf

**[CTX7-URDF-002]** Open Robotics. (2023). *URDF Tutorials*. http://wiki.ros.org/urdf/Tutorials

**[CTX7-XACRO-001]** Open Robotics. (2023). *Xacro - XML Macros for URDF*. http://wiki.ros.org/xacro

---

## Module 3: AI Robot Brain - Perception and Intelligence

### Computer Vision and Object Detection

**[CTX7-OPENCV-001]** OpenCV Team. (2023). *OpenCV Documentation*. https://docs.opencv.org/4.x/

**[CTX7-YOLO-001]** Ultralytics. (2023). *YOLOv8 Documentation*. https://docs.ultralytics.com/

**[CTX7-COCO-001]** Lin, T., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., & Zitnick, C. L. (2014). Microsoft COCO: Common Objects in Context. In *Computer Vision – ECCV 2014* (pp. 740-755). Springer. https://cocodataset.org/

### SLAM and Navigation

**[CTX7-NAV2-001]** Open Navigation. (2023). *Navigation2 Documentation*. https://navigation.ros.org/

**[CTX7-SLAM-001]** Open Robotics. (2023). *SLAM Toolbox Documentation*. https://github.com/SteveMacenski/slam_toolbox

**[CTX7-VSLAM-001]** Mur-Artal, R., Montiel, J. M. M., & Tardós, J. D. (2015). ORB-SLAM: A versatile and accurate monocular SLAM system. *IEEE Transactions on Robotics*, 31(5), 1147-1163. https://doi.org/10.1109/TRO.2015.2463671

### Intel RealSense

**[CTX7-REALSENSE-001]** Intel Corporation. (2023). *Intel RealSense D435i Documentation*. https://www.intelrealsense.com/depth-camera-d435i/

**[CTX7-REALSENSE-002]** Intel Corporation. (2023). *librealsense SDK*. https://github.com/IntelRealSense/librealsense

**[CTX7-REALSENSE-ROS-001]** Intel Corporation. (2023). *ROS 2 Wrapper for Intel RealSense*. https://github.com/IntelRealSense/realsense-ros

---

## Module 4: Vision-Language-Action Models

### Large Language Models

**[CTX7-CLAUDE-001]** Anthropic. (2024). *Claude API Documentation*. https://docs.anthropic.com/

**[CTX7-CLAUDE-002]** Anthropic. (2024). *Introducing Claude Sonnet 4.5*. https://www.anthropic.com/news/claude-sonnet-4-5

**[CTX7-LLM-ROBOTICS-001]** Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., ... & Zeng, A. (2022). Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. In *Conference on Robot Learning (CoRL)*. https://say-can.github.io/

### Voice Recognition

**[CTX7-WHISPER-001]** Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2022). Robust Speech Recognition via Large-Scale Weak Supervision. *arXiv preprint arXiv:2212.04356*. https://arxiv.org/abs/2212.04356

**[CTX7-WHISPER-002]** OpenAI. (2023). *Whisper Documentation*. https://github.com/openai/whisper

### Vision-Language Models

**[CTX7-VLA-001]** Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabis, J., Finn, C., ... & Zitkovich, B. (2023). RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control. In *Conference on Robot Learning (CoRL)*. https://robotics-transformer2.github.io/

**[CTX7-VLA-002]** Driess, D., Xia, F., Sajjadi, M. S., Lynch, C., Chowdhery, A., Ichter, B., ... & Florence, P. (2023). PaLM-E: An Embodied Multimodal Language Model. In *International Conference on Machine Learning (ICML)*. https://palm-e.github.io/

---

## Module 5: Capstone - Autonomous Humanoid System

### Robotics System Integration

**[CTX7-ROS2-INTEGRATION-001]** Macenski, S., Foote, T., Gerkey, B., Lalancette, C., & Woodall, W. (2022). Robot Operating System 2: Design, architecture, and uses in the wild. *Science Robotics*, 7(66), eabm6074. https://doi.org/10.1126/scirobotics.abm6074

**[CTX7-BEHAVIOR-TREES-001]** Colledanchise, M., & Ögren, P. (2018). *Behavior Trees in Robotics and AI: An Introduction*. CRC Press. https://arxiv.org/abs/1709.00084

### Manipulation and Grasping

**[CTX7-GRASP-001]** Bohg, J., Morales, A., Asfour, T., & Kragic, D. (2014). Data-driven grasp synthesis—A survey. *IEEE Transactions on Robotics*, 30(2), 289-309. https://doi.org/10.1109/TRO.2013.2289018

**[CTX7-MOVEIT-001]** MoveIt Maintainers. (2023). *MoveIt 2 Documentation*. https://moveit.picknik.ai/

### Dynamixel Servos

**[CTX7-DYNAMIXEL-001]** ROBOTIS. (2023). *Dynamixel XM430 e-Manual*. https://emanual.robotis.com/docs/en/dxl/x/xm430-w350/

**[CTX7-DYNAMIXEL-SDK-001]** ROBOTIS. (2023). *Dynamixel SDK Documentation*. https://emanual.robotis.com/docs/en/software/dynamixel/dynamixel_sdk/overview/

---

## General References

### Embedded Computing

**[CTX7-JETSON-001]** NVIDIA. (2023). *Jetson Orin Nano Developer Kit*. https://developer.nvidia.com/embedded/jetson-orin-nano-developer-kit

**[CTX7-JETSON-002]** NVIDIA. (2023). *JetPack SDK Documentation*. https://developer.nvidia.com/embedded/jetpack

### Docker and Containerization

**[CTX7-DOCKER-001]** Docker, Inc. (2023). *Docker Documentation*. https://docs.docker.com/

**[CTX7-NVIDIA-DOCKER-001]** NVIDIA. (2023). *NVIDIA Container Toolkit*. https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/

### Python and ML Frameworks

**[CTX7-PYTORCH-001]** Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. In *Advances in Neural Information Processing Systems* (pp. 8024-8035). https://pytorch.org/

**[CTX7-NUMPY-001]** Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., ... & Oliphant, T. E. (2020). Array programming with NumPy. *Nature*, 585(7825), 357-362. https://doi.org/10.1038/s41586-020-2649-2

### Software Engineering

**[CTX7-GIT-001]** Chacon, S., & Straub, B. (2014). *Pro Git* (2nd ed.). Apress. https://git-scm.com/book/en/v2

**[CTX7-GITHUB-ACTIONS-001]** GitHub, Inc. (2023). *GitHub Actions Documentation*. https://docs.github.com/en/actions

**[CTX7-PYTEST-001]** pytest developers. (2023). *pytest Documentation*. https://docs.pytest.org/

---

## Research Papers

### Foundational Robotics

**[RP-001]** Brooks, R. A. (1986). A robust layered control system for a mobile robot. *IEEE Journal on Robotics and Automation*, 2(1), 14-23. https://doi.org/10.1109/JRA.1986.1087032

**[RP-002]** Khatib, O. (1986). Real-time obstacle avoidance for manipulators and mobile robots. *The International Journal of Robotics Research*, 5(1), 90-98. https://doi.org/10.1177/027836498600500106

### Modern AI for Robotics

**[RP-003]** Levine, S., Pastor, P., Krizhevsky, A., Ibarz, J., & Quillen, D. (2018). Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. *The International Journal of Robotics Research*, 37(4-5), 421-436. https://doi.org/10.1177/0278364917710318

**[RP-004]** Ichter, B., Pavone, M., & Schaal, S. (2018). Robot motion planning in learned latent spaces. *IEEE Robotics and Automation Letters*, 4(3), 2407-2414. https://doi.org/10.1109/LRA.2019.2901394

---

## How to Add Citations

**For Contributors**:

1. Add citation metadata to `.context7/metadata/citations.json`
2. Run citation generation script:
   ```bash
   python3 scripts/citations/context7_to_apa.py
   ```
3. Verify output in `docs/appendices/citations.md`
4. Submit pull request with both files

**Citation Metadata Format**:
```json
{
  "id": "CTX7-EXAMPLE-001",
  "type": "documentation",
  "authors": ["Author Name"],
  "year": 2023,
  "title": "Document Title",
  "url": "https://example.com",
  "doi": null,
  "module": "module-01"
}
```

---

## Citation Statistics

**Total Citations**: TBD (to be populated from Context7)

**By Module**:
- Module 1 (ROS 2): Target 15 citations
- Module 2 (Digital Twin): Target 20 citations
- Module 3 (AI Brain): Target 25 citations
- Module 4 (VLA): Target 30 citations
- Module 5 (Capstone): Target 60 citations

**By Type**:
- Official Documentation: ~60%
- Research Papers: ~25%
- Vendor Guides: ~15%

---

**Found a broken link or missing citation?** Report it via [GitHub Issues](https://github.com/asadaligith/AI-Humanoid-Robotics-Book/issues) with the citation ID.

**Last Auto-Generated**: Run `python3 scripts/citations/context7_to_apa.py` to update
